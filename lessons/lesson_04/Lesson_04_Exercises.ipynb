{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Building Agents with LangChain\n",
    "## From Manual Agents to Framework-Based Implementation\n",
    "\n",
    "**Course**: Development of Agentic AI Systems for Advertising Campaign Analysis using Langchain Framework\n",
    "\n",
    "**Duration**: 60-90 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Transform the manual ReAct agent from Lesson 3 into a LangChain-based implementation\n",
    "2. Create custom tools using LangChain's Tool abstraction\n",
    "3. Build and run your first LangChain agent with GROQ\n",
    "4. Compare agent behavior with different configurations\n",
    "5. Design multi-agent architectures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Theory: Why Use a Framework?\n",
    "\n",
    "In Lesson 3, we built agents manually using raw LLM API calls. While educational, this approach has limitations:\n",
    "\n",
    "| Manual Approach (Lesson 3) | Framework Approach (LangChain) |\n",
    "|---------------------------|--------------------------------|\n",
    "| Custom JSON parsing | Built-in parsing and error handling |\n",
    "| Manual tool dispatch | Automatic tool selection and execution |\n",
    "| No memory abstraction | Ready-to-use memory components |\n",
    "| Reinventing patterns | Battle-tested implementations |\n",
    "\n",
    "**LangChain provides:**\n",
    "- **Tool abstraction**: Define tools once, use everywhere\n",
    "- **Agent executors**: Handle the ReAct loop automatically\n",
    "- **Prompt templates**: Reusable, parameterized prompts\n",
    "- **Memory systems**: Conversation history management\n",
    "- **Multi-provider support**: Same code works with different LLMs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T09:57:07.924288Z",
     "start_time": "2025-12-03T09:57:02.916249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting langchain-groq\r\n",
      "  Downloading langchain_groq-1.1.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting langchain-core\r\n",
      "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (1.2.1)\r\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\r\n",
      "  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain) (2.12.5)\r\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\r\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\r\n",
      "  Downloading langsmith-0.4.53-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core) (25.0)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core) (9.1.2)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core) (4.15.0)\r\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core)\r\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\r\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\r\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\r\n",
      "  Downloading langgraph_sdk-0.2.12-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\r\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\r\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\r\n",
      "  Downloading ormsgpack-1.12.0-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\r\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\r\n",
      "  Downloading orjson-3.11.4-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\r\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\r\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\r\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\r\n",
      "  Downloading uuid_utils-0.12.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.1 kB)\r\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\r\n",
      "  Downloading zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\r\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\r\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\r\n",
      "  Downloading groq-0.37.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\r\n",
      "Downloading langchain-1.1.0-py3-none-any.whl (101 kB)\r\n",
      "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\r\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\r\n",
      "Downloading langgraph-1.0.4-py3-none-any.whl (157 kB)\r\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\r\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\r\n",
      "Downloading langgraph_sdk-0.2.12-py3-none-any.whl (60 kB)\r\n",
      "Downloading langsmith-0.4.53-py3-none-any.whl (411 kB)\r\n",
      "Downloading uuid_utils-0.12.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (603 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.2/603.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_groq-1.1.0-py3-none-any.whl (19 kB)\r\n",
      "Downloading groq-0.37.0-py3-none-any.whl (137 kB)\r\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Downloading orjson-3.11.4-cp313-cp313-macosx_15_0_arm64.whl (128 kB)\r\n",
      "Downloading ormsgpack-1.12.0-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (369 kB)\r\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Downloading zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.4/640.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: zstandard, xxhash, uuid-utils, ormsgpack, orjson, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langgraph-sdk, groq, langchain-core, langgraph-checkpoint, langchain-groq, langgraph-prebuilt, langgraph, langchain\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [langchain]17\u001b[0m [langchain]core]\r\n",
      "\u001b[1A\u001b[2KSuccessfully installed groq-0.37.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.1.0 langchain-core-1.1.0 langchain-groq-1.1.0 langgraph-1.0.4 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.12 langsmith-0.4.53 orjson-3.11.4 ormsgpack-1.12.0 requests-toolbelt-1.0.0 uuid-utils-0.12.0 xxhash-3.6.0 zstandard-0.25.0\r\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install langchain langchain-groq langchain-core python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:05.813526Z",
     "start_time": "2025-12-03T10:47:05.805145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.agents import create_agent\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Configuration\n",
    "\n",
    "We'll use **GROQ** as our LLM provider for fast inference.\n",
    "\n",
    "**Get your API key**: https://console.groq.com\n",
    "\n",
    "**Available Models**:\n",
    "| Model | Description | Input Price | Output Price |\n",
    "|-------|-------------|-------------|---------------|\n",
    "| Llama 3.3 70B | Versatile, high-performance | $0.59/1M | $0.79/1M |\n",
    "| Llama 3.1 8B | Fast, efficient for simple tasks | $0.05/1M | $0.08/1M |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:08.362352Z",
     "start_time": "2025-12-03T10:47:08.360439Z"
    }
   },
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"\"\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:09.439364Z",
     "start_time": "2025-12-03T10:47:09.198393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: Hello, LangChain!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "# Quick test\n",
    "response = llm.invoke(\"Say 'Hello, LangChain!' in one line.\")\n",
    "print(f\"LLM Response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: From Manual to LangChain - Tool Implementation\n",
    "\n",
    "### Lesson 3 Recap: Manual Tool Definition\n",
    "\n",
    "In Lesson 3, we defined tools like this:\n",
    "```python\n",
    "TTVAM_TOOLS = [\n",
    "    {\n",
    "        \"name\": \"get_campaign_performance\",\n",
    "        \"description\": \"Retrieves performance data...\",\n",
    "        \"parameters\": {...}\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "### LangChain Approach: Tool Objects\n",
    "\n",
    "LangChain uses `Tool` objects that combine the function with its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:11.309561Z",
     "start_time": "2025-12-03T10:47:11.306574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 campaigns\n"
     ]
    }
   ],
   "source": [
    "# Mock TTVAM Campaign Database (same as Lesson 3)\n",
    "MOCK_CAMPAIGNS = {\n",
    "    \"1234\": {\n",
    "        \"name\": \"Spring Campaign 2024\",\n",
    "        \"broadcaster\": \"MTV\",\n",
    "        \"reach\": 48.5,\n",
    "        \"frequency\": 3.8,\n",
    "        \"impacts\": 5200000,\n",
    "        \"target\": \"Adults 25-54\",\n",
    "        \"period_start\": \"2024-03-01\",\n",
    "        \"period_end\": \"2024-03-31\"\n",
    "    },\n",
    "    \"5678\": {\n",
    "        \"name\": \"Summer Campaign 2024\",\n",
    "        \"broadcaster\": \"Sanoma\",\n",
    "        \"reach\": 52.3,\n",
    "        \"frequency\": 4.2,\n",
    "        \"impacts\": 6100000,\n",
    "        \"target\": \"Adults 25-54\",\n",
    "        \"period_start\": \"2024-06-01\",\n",
    "        \"period_end\": \"2024-06-30\"\n",
    "    },\n",
    "    \"9012\": {\n",
    "        \"name\": \"Autumn Campaign 2024\",\n",
    "        \"broadcaster\": \"MTV\",\n",
    "        \"reach\": 45.2,\n",
    "        \"frequency\": 3.5,\n",
    "        \"impacts\": 4800000,\n",
    "        \"target\": \"Female 25-44\",\n",
    "        \"period_start\": \"2024-09-01\",\n",
    "        \"period_end\": \"2024-09-30\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Loaded {len(MOCK_CAMPAIGNS)} campaigns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Creating a LangChain Tool\n",
    "\n",
    "Let's transform the `get_campaign_performance` function from Lesson 3 into a LangChain Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:12.587791Z",
     "start_time": "2025-12-03T10:47:12.577901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign Data for Spotgate 1234:\n",
      "Name: Spring Campaign 2024\n",
      "Broadcaster: MTV\n",
      "Target: Adults 25-54\n",
      "Period: 2024-03-01 to 2024-03-31\n",
      "Reach: 48.5%\n",
      "Frequency: 3.8\n",
      "Total Impacts: 5,200,000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def get_campaign_data(spotgate_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve campaign data by Spotgate code.\n",
    "    \n",
    "    Args:\n",
    "        spotgate_code: The Spotgate identification code\n",
    "        \n",
    "    Returns:\n",
    "        String with campaign data or error message\n",
    "    \"\"\"\n",
    "    if spotgate_code not in MOCK_CAMPAIGNS:\n",
    "        return f\"Error: Campaign with Spotgate code '{spotgate_code}' not found.\"\n",
    "    \n",
    "    campaign = MOCK_CAMPAIGNS[spotgate_code]\n",
    "    \n",
    "    result = f\"\"\"Campaign Data for Spotgate {spotgate_code}:\n",
    "Name: {campaign['name']}\n",
    "Broadcaster: {campaign['broadcaster']}\n",
    "Target: {campaign['target']}\n",
    "Period: {campaign['period_start']} to {campaign['period_end']}\n",
    "Reach: {campaign['reach']}%\n",
    "Frequency: {campaign['frequency']}\n",
    "Total Impacts: {campaign['impacts']:,}\"\"\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the tool\n",
    "print(get_campaign_data.invoke(\"1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:15.094684Z",
     "start_time": "2025-12-03T10:47:15.089837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool created: get_campaign_data\n",
      "Description: Retrieve campaign data by Spotgate code.\n",
      "\n",
      "Args:\n",
      "    spotgate_code: The Spotgate identification code\n",
      "\n",
      "Returns:\n",
      "    String with campaign data or error message\n"
     ]
    }
   ],
   "source": [
    "# The @tool decorator already created a LangChain Tool\n",
    "# Let's inspect it\n",
    "print(f\"Tool created: {get_campaign_data.name}\")\n",
    "print(f\"Description: {get_campaign_data.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: More Tools for Campaign Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:17.309318Z",
     "start_time": "2025-12-03T10:47:17.302344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign Comparison: 1234 vs 5678\n",
      "\n",
      "Campaign 1: Spring Campaign 2024\n",
      "- Reach: 48.5%\n",
      "- Frequency: 3.8\n",
      "- Impacts: 5,200,000\n",
      "\n",
      "Campaign 2: Summer Campaign 2024\n",
      "- Reach: 52.3%\n",
      "- Frequency: 4.2\n",
      "- Impacts: 6,100,000\n",
      "\n",
      "Analysis:\n",
      "- Reach difference: 3.8% (Campaign 2 higher)\n",
      "- Campaign 2 achieved better reach.\n",
      "- Campaign 2 generated more impacts.\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def compare_campaigns(campaign_codes: str) -> str:\n",
    "    \"\"\"\n",
    "    Compare performance metrics of two campaigns.\n",
    "    \n",
    "    Args:\n",
    "        campaign_codes: Two comma-separated Spotgate codes (e.g., '1234,5678')\n",
    "        \n",
    "    Returns:\n",
    "        String with comparison of reach, frequency, and impacts\n",
    "    \"\"\"\n",
    "    codes = [code.strip() for code in campaign_codes.split(\",\")]\n",
    "    \n",
    "    if len(codes) != 2:\n",
    "        return f\"Error: Please provide exactly 2 campaign codes. You provided {len(codes)}.\"\n",
    "    \n",
    "    missing_codes = [code for code in codes if code not in MOCK_CAMPAIGNS]\n",
    "    if missing_codes:\n",
    "        return f\"Error: Campaigns not found: {', '.join(missing_codes)}\"\n",
    "    \n",
    "    camp1 = MOCK_CAMPAIGNS[codes[0]]\n",
    "    camp2 = MOCK_CAMPAIGNS[codes[1]]\n",
    "    \n",
    "    result = f\"\"\"Campaign Comparison: {codes[0]} vs {codes[1]}\n",
    "\n",
    "Campaign 1: {camp1['name']}\n",
    "- Reach: {camp1['reach']}%\n",
    "- Frequency: {camp1['frequency']}\n",
    "- Impacts: {camp1['impacts']:,}\n",
    "\n",
    "Campaign 2: {camp2['name']}\n",
    "- Reach: {camp2['reach']}%\n",
    "- Frequency: {camp2['frequency']}\n",
    "- Impacts: {camp2['impacts']:,}\n",
    "\n",
    "Analysis:\n",
    "- Reach difference: {abs(camp1['reach'] - camp2['reach']):.1f}% ({'Campaign 1 higher' if camp1['reach'] > camp2['reach'] else 'Campaign 2 higher'})\n",
    "- {'Campaign 1' if camp1['reach'] > camp2['reach'] else 'Campaign 2'} achieved better reach.\n",
    "- {'Campaign 1' if camp1['impacts'] > camp2['impacts'] else 'Campaign 2'} generated more impacts.\"\"\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_kpi(params: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate KPIs from campaign metrics.\n",
    "    \n",
    "    Args:\n",
    "        params: Format 'spotgate_code,budget' (e.g., '1234,50000')\n",
    "        \n",
    "    Returns:\n",
    "        String with calculated KPIs (CPM, cost per reach point)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = params.split(\",\")\n",
    "        spotgate_code = parts[0].strip()\n",
    "        budget = float(parts[1].strip())\n",
    "    except (IndexError, ValueError):\n",
    "        return \"Error: Input should be 'spotgate_code,budget' (e.g., '1234,50000')\"\n",
    "    \n",
    "    if spotgate_code not in MOCK_CAMPAIGNS:\n",
    "        return f\"Error: Campaign '{spotgate_code}' not found.\"\n",
    "    \n",
    "    campaign = MOCK_CAMPAIGNS[spotgate_code]\n",
    "    \n",
    "    # Calculate KPIs\n",
    "    cpm = (budget / campaign['impacts']) * 1000\n",
    "    cost_per_reach_point = budget / campaign['reach']\n",
    "    \n",
    "    result = f\"\"\"KPI Analysis for {campaign['name']}:\n",
    "\n",
    "Input Data:\n",
    "- Budget: €{budget:,.2f}\n",
    "- Impacts: {campaign['impacts']:,}\n",
    "- Reach: {campaign['reach']}%\n",
    "\n",
    "Calculated KPIs:\n",
    "- CPM (Cost per Mille): €{cpm:.2f}\n",
    "- Cost per Reach Point: €{cost_per_reach_point:.2f}\n",
    "- Efficiency: {'Good' if cpm < 10 else 'Average' if cpm < 15 else 'High cost'}\"\"\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test\n",
    "print(compare_campaigns.invoke(\"1234,5678\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:17.972299Z",
     "start_time": "2025-12-03T10:47:17.969772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 tools:\n",
      "  - get_campaign_data\n",
      "  - compare_campaigns\n",
      "  - calculate_kpi\n"
     ]
    }
   ],
   "source": [
    "# Create all tools list - these are already tool objects from the @tool decorator\n",
    "tools = [\n",
    "    get_campaign_data,\n",
    "    compare_campaigns,\n",
    "    calculate_kpi\n",
    "]\n",
    "\n",
    "print(f\"Created {len(tools)} tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building the LangChain Agent\n",
    "\n",
    "### Creating the Agent\n",
    "\n",
    "LangChain's new API simplifies agent creation. Instead of managing prompts and executors separately,\n",
    "we use `create_agent()` which handles the ReAct loop automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:19.404233Z",
     "start_time": "2025-12-03T10:47:19.388509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ready!\n"
     ]
    }
   ],
   "source": [
    "# Create the agent with tools\n",
    "system_prompt = \"\"\"You are an expert advertising campaign analyst with access to the TTVAM database.\n",
    "\n",
    "Answer questions about campaigns using the available tools. Think step by step:\n",
    "1. Identify which tool(s) you need to use\n",
    "2. Call the tools with the correct parameters\n",
    "3. Analyze the results\n",
    "4. Provide a clear answer to the user\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    debug=True  # Show reasoning steps\n",
    ")\n",
    "\n",
    "print(\"Agent ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Agent\n",
    "\n",
    "Watch how the agent reasons through queries (debug=True shows the ReAct cycle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:48:59.556697Z",
     "start_time": "2025-12-03T10:48:59.037062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the reach of campaign 1234?\n",
      "============================================================\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What is the reach of campaign 1234?', additional_kwargs={}, response_metadata={}, id='db0bbb60-da6f-4ed4-b846-884ec6c255fe')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8eng1rzfe', 'function': {'arguments': '{\"spotgate_code\":\"1234\"}', 'name': 'get_campaign_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 633, 'total_tokens': 651, 'completion_time': 0.036528581, 'completion_tokens_details': None, 'prompt_time': 0.033811693, 'prompt_tokens_details': None, 'queue_time': 0.050683454, 'total_time': 0.070340274}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--04d6131b-c6ea-48c9-a003-2124eadadcc0-0', tool_calls=[{'name': 'get_campaign_data', 'args': {'spotgate_code': '1234'}, 'id': '8eng1rzfe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 633, 'output_tokens': 18, 'total_tokens': 651})]}}\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8eng1rzfe', 'function': {'arguments': '{\"spotgate_code\":\"1234\"}', 'name': 'get_campaign_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 633, 'total_tokens': 651, 'completion_time': 0.036528581, 'completion_tokens_details': None, 'prompt_time': 0.033811693, 'prompt_tokens_details': None, 'queue_time': 0.050683454, 'total_time': 0.070340274}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--04d6131b-c6ea-48c9-a003-2124eadadcc0-0', tool_calls=[{'name': 'get_campaign_data', 'args': {'spotgate_code': '1234'}, 'id': '8eng1rzfe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 633, 'output_tokens': 18, 'total_tokens': 651})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What is the reach of campaign 1234?', additional_kwargs={}, response_metadata={}, id='db0bbb60-da6f-4ed4-b846-884ec6c255fe'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8eng1rzfe', 'function': {'arguments': '{\"spotgate_code\":\"1234\"}', 'name': 'get_campaign_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 633, 'total_tokens': 651, 'completion_time': 0.036528581, 'completion_tokens_details': None, 'prompt_time': 0.033811693, 'prompt_tokens_details': None, 'queue_time': 0.050683454, 'total_time': 0.070340274}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--04d6131b-c6ea-48c9-a003-2124eadadcc0-0', tool_calls=[{'name': 'get_campaign_data', 'args': {'spotgate_code': '1234'}, 'id': '8eng1rzfe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 633, 'output_tokens': 18, 'total_tokens': 651})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='Campaign Data for Spotgate 1234:\\nName: Spring Campaign 2024\\nBroadcaster: MTV\\nTarget: Adults 25-54\\nPeriod: 2024-03-01 to 2024-03-31\\nReach: 48.5%\\nFrequency: 3.8\\nTotal Impacts: 5,200,000', name='get_campaign_data', id='27f0a796-4487-4165-bdc1-a84925ce792e', tool_call_id='8eng1rzfe')]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Campaign Data for Spotgate 1234:\\nName: Spring Campaign 2024\\nBroadcaster: MTV\\nTarget: Adults 25-54\\nPeriod: 2024-03-01 to 2024-03-31\\nReach: 48.5%\\nFrequency: 3.8\\nTotal Impacts: 5,200,000', name='get_campaign_data', id='27f0a796-4487-4165-bdc1-a84925ce792e', tool_call_id='8eng1rzfe')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What is the reach of campaign 1234?', additional_kwargs={}, response_metadata={}, id='db0bbb60-da6f-4ed4-b846-884ec6c255fe'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8eng1rzfe', 'function': {'arguments': '{\"spotgate_code\":\"1234\"}', 'name': 'get_campaign_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 633, 'total_tokens': 651, 'completion_time': 0.036528581, 'completion_tokens_details': None, 'prompt_time': 0.033811693, 'prompt_tokens_details': None, 'queue_time': 0.050683454, 'total_time': 0.070340274}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--04d6131b-c6ea-48c9-a003-2124eadadcc0-0', tool_calls=[{'name': 'get_campaign_data', 'args': {'spotgate_code': '1234'}, 'id': '8eng1rzfe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 633, 'output_tokens': 18, 'total_tokens': 651}), ToolMessage(content='Campaign Data for Spotgate 1234:\\nName: Spring Campaign 2024\\nBroadcaster: MTV\\nTarget: Adults 25-54\\nPeriod: 2024-03-01 to 2024-03-31\\nReach: 48.5%\\nFrequency: 3.8\\nTotal Impacts: 5,200,000', name='get_campaign_data', id='27f0a796-4487-4165-bdc1-a84925ce792e', tool_call_id='8eng1rzfe')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='The reach of campaign 1234 is 48.5%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 733, 'total_tokens': 747, 'completion_time': 0.029988423, 'completion_tokens_details': None, 'prompt_time': 0.039812838, 'prompt_tokens_details': None, 'queue_time': 0.154660823, 'total_time': 0.069801261}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--16955ec7-f2e7-4f7f-be48-296ceb60cac4-0', usage_metadata={'input_tokens': 733, 'output_tokens': 14, 'total_tokens': 747})]}}\n",
      "{'model': {'messages': [AIMessage(content='The reach of campaign 1234 is 48.5%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 733, 'total_tokens': 747, 'completion_time': 0.029988423, 'completion_tokens_details': None, 'prompt_time': 0.039812838, 'prompt_tokens_details': None, 'queue_time': 0.154660823, 'total_time': 0.069801261}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--16955ec7-f2e7-4f7f-be48-296ceb60cac4-0', usage_metadata={'input_tokens': 733, 'output_tokens': 14, 'total_tokens': 747})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='What is the reach of campaign 1234?', additional_kwargs={}, response_metadata={}, id='db0bbb60-da6f-4ed4-b846-884ec6c255fe'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8eng1rzfe', 'function': {'arguments': '{\"spotgate_code\":\"1234\"}', 'name': 'get_campaign_data'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 633, 'total_tokens': 651, 'completion_time': 0.036528581, 'completion_tokens_details': None, 'prompt_time': 0.033811693, 'prompt_tokens_details': None, 'queue_time': 0.050683454, 'total_time': 0.070340274}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--04d6131b-c6ea-48c9-a003-2124eadadcc0-0', tool_calls=[{'name': 'get_campaign_data', 'args': {'spotgate_code': '1234'}, 'id': '8eng1rzfe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 633, 'output_tokens': 18, 'total_tokens': 651}), ToolMessage(content='Campaign Data for Spotgate 1234:\\nName: Spring Campaign 2024\\nBroadcaster: MTV\\nTarget: Adults 25-54\\nPeriod: 2024-03-01 to 2024-03-31\\nReach: 48.5%\\nFrequency: 3.8\\nTotal Impacts: 5,200,000', name='get_campaign_data', id='27f0a796-4487-4165-bdc1-a84925ce792e', tool_call_id='8eng1rzfe'), AIMessage(content='The reach of campaign 1234 is 48.5%.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 733, 'total_tokens': 747, 'completion_time': 0.029988423, 'completion_tokens_details': None, 'prompt_time': 0.039812838, 'prompt_tokens_details': None, 'queue_time': 0.154660823, 'total_time': 0.069801261}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--16955ec7-f2e7-4f7f-be48-296ceb60cac4-0', usage_metadata={'input_tokens': 733, 'output_tokens': 14, 'total_tokens': 747})]}\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Query 1: Simple data retrieval\n",
    "query1 = \"What is the reach of campaign 1234?\"\n",
    "print(f\"Query: {query1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Stream the agent response\n",
    "for chunk in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query1}]}, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:47:58.985982Z",
     "start_time": "2025-12-03T10:47:57.886552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Compare campaigns 1234 and 5678. Which one performed better?\n",
      "============================================================\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compare campaigns 1234 and 5678. Which one performed better?', additional_kwargs={}, response_metadata={}, id='c3548e07-d25e-4993-98f0-9da3ebc9d8f4')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659})]}}\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compare campaigns 1234 and 5678. Which one performed better?', additional_kwargs={}, response_metadata={}, id='c3548e07-d25e-4993-98f0-9da3ebc9d8f4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='84fb6485-9953-48d5-b199-c9f9fe063230', tool_call_id='2rr2htsca')]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='84fb6485-9953-48d5-b199-c9f9fe063230', tool_call_id='2rr2htsca')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compare campaigns 1234 and 5678. Which one performed better?', additional_kwargs={}, response_metadata={}, id='c3548e07-d25e-4993-98f0-9da3ebc9d8f4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659}), ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='84fb6485-9953-48d5-b199-c9f9fe063230', tool_call_id='2rr2htsca')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm83tppbvr', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 787, 'total_tokens': 877, 'completion_time': 0.19453518, 'completion_tokens_details': None, 'prompt_time': 0.042250503, 'prompt_tokens_details': None, 'queue_time': 0.050326952, 'total_time': 0.236785683}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9115ee3-2090-4231-86fc-010828a2f85e-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': 'm83tppbvr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 787, 'output_tokens': 90, 'total_tokens': 877})]}}\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm83tppbvr', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 787, 'total_tokens': 877, 'completion_time': 0.19453518, 'completion_tokens_details': None, 'prompt_time': 0.042250503, 'prompt_tokens_details': None, 'queue_time': 0.050326952, 'total_time': 0.236785683}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9115ee3-2090-4231-86fc-010828a2f85e-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': 'm83tppbvr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 787, 'output_tokens': 90, 'total_tokens': 877})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compare campaigns 1234 and 5678. Which one performed better?', additional_kwargs={}, response_metadata={}, id='c3548e07-d25e-4993-98f0-9da3ebc9d8f4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659}), ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='84fb6485-9953-48d5-b199-c9f9fe063230', tool_call_id='2rr2htsca'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm83tppbvr', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 787, 'total_tokens': 877, 'completion_time': 0.19453518, 'completion_tokens_details': None, 'prompt_time': 0.042250503, 'prompt_tokens_details': None, 'queue_time': 0.050326952, 'total_time': 0.236785683}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9115ee3-2090-4231-86fc-010828a2f85e-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': 'm83tppbvr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 787, 'output_tokens': 90, 'total_tokens': 877})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='204d36f4-a236-4cfa-93d9-af694c9de11c', tool_call_id='m83tppbvr')]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='204d36f4-a236-4cfa-93d9-af694c9de11c', tool_call_id='m83tppbvr')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compare campaigns 1234 and 5678. Which one performed better?', additional_kwargs={}, response_metadata={}, id='c3548e07-d25e-4993-98f0-9da3ebc9d8f4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659}), ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='84fb6485-9953-48d5-b199-c9f9fe063230', tool_call_id='2rr2htsca'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm83tppbvr', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 787, 'total_tokens': 877, 'completion_time': 0.19453518, 'completion_tokens_details': None, 'prompt_time': 0.042250503, 'prompt_tokens_details': None, 'queue_time': 0.050326952, 'total_time': 0.236785683}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9115ee3-2090-4231-86fc-010828a2f85e-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': 'm83tppbvr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 787, 'output_tokens': 90, 'total_tokens': 877}), ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='204d36f4-a236-4cfa-93d9-af694c9de11c', tool_call_id='m83tppbvr')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='Based on the comparison, Campaign 5678 (Summer Campaign 2024) performed better than Campaign 1234 (Spring Campaign 2024) with a higher reach of 52.3% and more impacts of 6,100,000.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 936, 'total_tokens': 988, 'completion_time': 0.109976037, 'completion_tokens_details': None, 'prompt_time': 0.04625035, 'prompt_tokens_details': None, 'queue_time': 0.050038975, 'total_time': 0.156226387}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1b3a5075-c885-45e7-b251-654b6f2b17c7-0', usage_metadata={'input_tokens': 936, 'output_tokens': 52, 'total_tokens': 988})]}}\n",
      "{'model': {'messages': [AIMessage(content='Based on the comparison, Campaign 5678 (Summer Campaign 2024) performed better than Campaign 1234 (Spring Campaign 2024) with a higher reach of 52.3% and more impacts of 6,100,000.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 936, 'total_tokens': 988, 'completion_time': 0.109976037, 'completion_tokens_details': None, 'prompt_time': 0.04625035, 'prompt_tokens_details': None, 'queue_time': 0.050038975, 'total_time': 0.156226387}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1b3a5075-c885-45e7-b251-654b6f2b17c7-0', usage_metadata={'input_tokens': 936, 'output_tokens': 52, 'total_tokens': 988})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compare campaigns 1234 and 5678. Which one performed better?', additional_kwargs={}, response_metadata={}, id='c3548e07-d25e-4993-98f0-9da3ebc9d8f4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2rr2htsca', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 638, 'total_tokens': 659, 'completion_time': 0.040032876, 'completion_tokens_details': None, 'prompt_time': 0.072630921, 'prompt_tokens_details': None, 'queue_time': 0.154772602, 'total_time': 0.112663797}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7d83b061-5df4-41cc-aee7-101bb86e2503-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': '2rr2htsca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 21, 'total_tokens': 659}), ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='84fb6485-9953-48d5-b199-c9f9fe063230', tool_call_id='2rr2htsca'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm83tppbvr', 'function': {'arguments': '{\"campaign_codes\":\"1234,5678\"}', 'name': 'compare_campaigns'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 787, 'total_tokens': 877, 'completion_time': 0.19453518, 'completion_tokens_details': None, 'prompt_time': 0.042250503, 'prompt_tokens_details': None, 'queue_time': 0.050326952, 'total_time': 0.236785683}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a9115ee3-2090-4231-86fc-010828a2f85e-0', tool_calls=[{'name': 'compare_campaigns', 'args': {'campaign_codes': '1234,5678'}, 'id': 'm83tppbvr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 787, 'output_tokens': 90, 'total_tokens': 877}), ToolMessage(content='Campaign Comparison: 1234 vs 5678\\n\\nCampaign 1: Spring Campaign 2024\\n- Reach: 48.5%\\n- Frequency: 3.8\\n- Impacts: 5,200,000\\n\\nCampaign 2: Summer Campaign 2024\\n- Reach: 52.3%\\n- Frequency: 4.2\\n- Impacts: 6,100,000\\n\\nAnalysis:\\n- Reach difference: 3.8% (Campaign 2 higher)\\n- Campaign 2 achieved better reach.\\n- Campaign 2 generated more impacts.', name='compare_campaigns', id='204d36f4-a236-4cfa-93d9-af694c9de11c', tool_call_id='m83tppbvr'), AIMessage(content='Based on the comparison, Campaign 5678 (Summer Campaign 2024) performed better than Campaign 1234 (Spring Campaign 2024) with a higher reach of 52.3% and more impacts of 6,100,000.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 936, 'total_tokens': 988, 'completion_time': 0.109976037, 'completion_tokens_details': None, 'prompt_time': 0.04625035, 'prompt_tokens_details': None, 'queue_time': 0.050038975, 'total_time': 0.156226387}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1b3a5075-c885-45e7-b251-654b6f2b17c7-0', usage_metadata={'input_tokens': 936, 'output_tokens': 52, 'total_tokens': 988})]}\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Comparison (requires tool selection)\n",
    "query2 = \"Compare campaigns 1234 and 5678. Which one performed better?\"\n",
    "print(f\"Query: {query2}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for chunk in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query2}]}, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T10:48:30.262444Z",
     "start_time": "2025-12-03T10:48:29.845378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Calculate the CPM for campaign 1234 with a budget of 50000 euros\n",
      "============================================================\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Calculate the CPM for campaign 1234 with a budget of 50000 euros', additional_kwargs={}, response_metadata={}, id='8d844187-c4d4-41c3-b946-51fbceccb99f')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'h8kb2qvfz', 'function': {'arguments': '{\"params\":\"1234,50000\"}', 'name': 'calculate_kpi'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 640, 'total_tokens': 660, 'completion_time': 0.028290999, 'completion_tokens_details': None, 'prompt_time': 0.033092004, 'prompt_tokens_details': None, 'queue_time': 0.05089829, 'total_time': 0.061383003}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9764fae0-f205-46b8-92e7-1a5ca5cdaee9-0', tool_calls=[{'name': 'calculate_kpi', 'args': {'params': '1234,50000'}, 'id': 'h8kb2qvfz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 640, 'output_tokens': 20, 'total_tokens': 660})]}}\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'h8kb2qvfz', 'function': {'arguments': '{\"params\":\"1234,50000\"}', 'name': 'calculate_kpi'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 640, 'total_tokens': 660, 'completion_time': 0.028290999, 'completion_tokens_details': None, 'prompt_time': 0.033092004, 'prompt_tokens_details': None, 'queue_time': 0.05089829, 'total_time': 0.061383003}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9764fae0-f205-46b8-92e7-1a5ca5cdaee9-0', tool_calls=[{'name': 'calculate_kpi', 'args': {'params': '1234,50000'}, 'id': 'h8kb2qvfz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 640, 'output_tokens': 20, 'total_tokens': 660})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Calculate the CPM for campaign 1234 with a budget of 50000 euros', additional_kwargs={}, response_metadata={}, id='8d844187-c4d4-41c3-b946-51fbceccb99f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'h8kb2qvfz', 'function': {'arguments': '{\"params\":\"1234,50000\"}', 'name': 'calculate_kpi'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 640, 'total_tokens': 660, 'completion_time': 0.028290999, 'completion_tokens_details': None, 'prompt_time': 0.033092004, 'prompt_tokens_details': None, 'queue_time': 0.05089829, 'total_time': 0.061383003}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9764fae0-f205-46b8-92e7-1a5ca5cdaee9-0', tool_calls=[{'name': 'calculate_kpi', 'args': {'params': '1234,50000'}, 'id': 'h8kb2qvfz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 640, 'output_tokens': 20, 'total_tokens': 660})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='KPI Analysis for Spring Campaign 2024:\\n\\nInput Data:\\n- Budget: €50,000.00\\n- Impacts: 5,200,000\\n- Reach: 48.5%\\n\\nCalculated KPIs:\\n- CPM (Cost per Mille): €9.62\\n- Cost per Reach Point: €1030.93\\n- Efficiency: Good', name='calculate_kpi', id='db83f86b-eed2-4087-9668-6a3ba22ffeab', tool_call_id='h8kb2qvfz')]}}\n",
      "{'tools': {'messages': [ToolMessage(content='KPI Analysis for Spring Campaign 2024:\\n\\nInput Data:\\n- Budget: €50,000.00\\n- Impacts: 5,200,000\\n- Reach: 48.5%\\n\\nCalculated KPIs:\\n- CPM (Cost per Mille): €9.62\\n- Cost per Reach Point: €1030.93\\n- Efficiency: Good', name='calculate_kpi', id='db83f86b-eed2-4087-9668-6a3ba22ffeab', tool_call_id='h8kb2qvfz')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Calculate the CPM for campaign 1234 with a budget of 50000 euros', additional_kwargs={}, response_metadata={}, id='8d844187-c4d4-41c3-b946-51fbceccb99f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'h8kb2qvfz', 'function': {'arguments': '{\"params\":\"1234,50000\"}', 'name': 'calculate_kpi'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 640, 'total_tokens': 660, 'completion_time': 0.028290999, 'completion_tokens_details': None, 'prompt_time': 0.033092004, 'prompt_tokens_details': None, 'queue_time': 0.05089829, 'total_time': 0.061383003}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9764fae0-f205-46b8-92e7-1a5ca5cdaee9-0', tool_calls=[{'name': 'calculate_kpi', 'args': {'params': '1234,50000'}, 'id': 'h8kb2qvfz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 640, 'output_tokens': 20, 'total_tokens': 660}), ToolMessage(content='KPI Analysis for Spring Campaign 2024:\\n\\nInput Data:\\n- Budget: €50,000.00\\n- Impacts: 5,200,000\\n- Reach: 48.5%\\n\\nCalculated KPIs:\\n- CPM (Cost per Mille): €9.62\\n- Cost per Reach Point: €1030.93\\n- Efficiency: Good', name='calculate_kpi', id='db83f86b-eed2-4087-9668-6a3ba22ffeab', tool_call_id='h8kb2qvfz')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='The CPM for campaign 1234 with a budget of 50000 euros is €9.62.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 748, 'total_tokens': 771, 'completion_time': 0.049931412, 'completion_tokens_details': None, 'prompt_time': 0.036872316, 'prompt_tokens_details': None, 'queue_time': 0.049951159, 'total_time': 0.086803728}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a712175f-7293-46a4-81ee-c54702a11a44-0', usage_metadata={'input_tokens': 748, 'output_tokens': 23, 'total_tokens': 771})]}}\n",
      "{'model': {'messages': [AIMessage(content='The CPM for campaign 1234 with a budget of 50000 euros is €9.62.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 748, 'total_tokens': 771, 'completion_time': 0.049931412, 'completion_tokens_details': None, 'prompt_time': 0.036872316, 'prompt_tokens_details': None, 'queue_time': 0.049951159, 'total_time': 0.086803728}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a712175f-7293-46a4-81ee-c54702a11a44-0', usage_metadata={'input_tokens': 748, 'output_tokens': 23, 'total_tokens': 771})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Calculate the CPM for campaign 1234 with a budget of 50000 euros', additional_kwargs={}, response_metadata={}, id='8d844187-c4d4-41c3-b946-51fbceccb99f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'h8kb2qvfz', 'function': {'arguments': '{\"params\":\"1234,50000\"}', 'name': 'calculate_kpi'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 640, 'total_tokens': 660, 'completion_time': 0.028290999, 'completion_tokens_details': None, 'prompt_time': 0.033092004, 'prompt_tokens_details': None, 'queue_time': 0.05089829, 'total_time': 0.061383003}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9764fae0-f205-46b8-92e7-1a5ca5cdaee9-0', tool_calls=[{'name': 'calculate_kpi', 'args': {'params': '1234,50000'}, 'id': 'h8kb2qvfz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 640, 'output_tokens': 20, 'total_tokens': 660}), ToolMessage(content='KPI Analysis for Spring Campaign 2024:\\n\\nInput Data:\\n- Budget: €50,000.00\\n- Impacts: 5,200,000\\n- Reach: 48.5%\\n\\nCalculated KPIs:\\n- CPM (Cost per Mille): €9.62\\n- Cost per Reach Point: €1030.93\\n- Efficiency: Good', name='calculate_kpi', id='db83f86b-eed2-4087-9668-6a3ba22ffeab', tool_call_id='h8kb2qvfz'), AIMessage(content='The CPM for campaign 1234 with a budget of 50000 euros is €9.62.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 748, 'total_tokens': 771, 'completion_time': 0.049931412, 'completion_tokens_details': None, 'prompt_time': 0.036872316, 'prompt_tokens_details': None, 'queue_time': 0.049951159, 'total_time': 0.086803728}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--a712175f-7293-46a4-81ee-c54702a11a44-0', usage_metadata={'input_tokens': 748, 'output_tokens': 23, 'total_tokens': 771})]}\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Multi-step reasoning (multiple tool calls)\n",
    "query3 = \"Calculate the CPM for campaign 1234 with a budget of 50000 euros\"\n",
    "print(f\"Query: {query3}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for chunk in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query3}]}, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Exercises\n",
    "\n",
    "Now it's your turn! Complete the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a New Tool\n",
    "\n",
    "Create a tool called `list_campaigns` that lists all available campaigns with their basic info.\n",
    "\n",
    "**Requirements:**\n",
    "- The tool should take no input (or accept an empty string)\n",
    "- Return a list of all campaigns with their names and Spotgate codes\n",
    "- Include the target audience for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: TODO - Implement the list_campaigns function\n",
    "# Don't forget to add the @tool decorator!\n",
    "\n",
    "@tool\n",
    "def list_campaigns(query: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    List all available campaigns in the database.\n",
    "    \n",
    "    Args:\n",
    "        query: Not used, accepts any input\n",
    "        \n",
    "    Returns:\n",
    "        String listing all campaigns with their codes and names\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hint: Loop through MOCK_CAMPAIGNS and format the output\n",
    "    pass\n",
    "\n",
    "# Test your function\n",
    "# print(list_campaigns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 continued: Convert to LangChain Tool\n",
    "\n",
    "# TODO: Add the @tool decorator to your list_campaigns function above\n",
    "# The @tool decorator will automatically create a LangChain tool from your function\n",
    "# No need to wrap it with Tool() - just add @tool before the function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Add Tool to Agent and Test\n",
    "\n",
    "Add your new `list_campaigns` tool to the agent and test it with these queries:\n",
    "1. \"What campaigns are available?\"\n",
    "2. \"Show me all campaigns targeting Adults 25-54\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: TODO - Create an enhanced agent with your new tool\n",
    "\n",
    "# enhanced_tools = tools + [list_campaigns]\n",
    "\n",
    "# TODO: Create a new agent with enhanced_tools\n",
    "# enhanced_agent = create_agent(\n",
    "#     model=llm,\n",
    "#     tools=enhanced_tools,\n",
    "#     system_prompt=system_prompt,\n",
    "#     debug=True\n",
    "# )\n",
    "\n",
    "# TODO: Test with the queries above\n",
    "# Example:\n",
    "# for chunk in enhanced_agent.stream(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What campaigns are available?\"}]},\n",
    "#     stream_mode=\"updates\"\n",
    "# ):\n",
    "#     print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Create a Report Generation Tool\n",
    "\n",
    "Create a tool that generates a brief executive summary for a campaign.\n",
    "\n",
    "**Requirements:**\n",
    "- Input: Spotgate code\n",
    "- Output: A formatted executive summary including:\n",
    "  - Campaign name and period\n",
    "  - Key metrics (reach, frequency, impacts)\n",
    "  - A performance assessment (good/average/poor based on reach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: TODO - Implement generate_report function\n",
    "\n",
    "def generate_report(spotgate_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an executive summary report for a campaign.\n",
    "    \n",
    "    Args:\n",
    "        spotgate_code: The Spotgate identification code\n",
    "        \n",
    "    Returns:\n",
    "        Formatted executive summary\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hint:\n",
    "    # 1. Check if campaign exists\n",
    "    # 2. Retrieve campaign data\n",
    "    # 3. Assess performance (reach > 50% = good, > 40% = average, else = needs improvement)\n",
    "    # 4. Format as executive summary\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "# print(generate_report(\"1234\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Multi-Agent Architecture Design\n",
    "\n",
    "Design a multi-agent system for comprehensive campaign analysis. Fill in the architecture below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: TODO - Design your multi-agent architecture\n",
    "\n",
    "multi_agent_design = {\n",
    "    \"architecture_type\": \"\",  # \"sequential\", \"hierarchical\", or \"parallel\"\n",
    "    \n",
    "    \"agents\": [\n",
    "        # TODO: Define at least 3 specialized agents\n",
    "        # Example:\n",
    "        # {\n",
    "        #     \"name\": \"Data Agent\",\n",
    "        #     \"role\": \"Retrieve campaign data\",\n",
    "        #     \"tools\": [\"get_campaign_data\", \"list_campaigns\"],\n",
    "        #     \"llm\": \"llama-3.1-8b (fast, simple tasks)\"\n",
    "        # }\n",
    "    ],\n",
    "    \n",
    "    \"workflow\": [\n",
    "        # TODO: Define the workflow steps\n",
    "        # Example:\n",
    "        # {\"step\": 1, \"agent\": \"Data Agent\", \"action\": \"Fetch data\"}\n",
    "    ],\n",
    "    \n",
    "    \"advantages\": [\n",
    "        # TODO: List at least 3 advantages of your design\n",
    "    ],\n",
    "    \n",
    "    \"challenges\": [\n",
    "        # TODO: List at least 2 potential challenges\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(json.dumps(multi_agent_design, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Error Handling\n",
    "\n",
    "Test your agent with edge cases and observe how it handles errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Test edge cases\n",
    "\n",
    "edge_cases = [\n",
    "    \"What is the reach of campaign 9999?\",  # Non-existent campaign\n",
    "    \"Compare campaigns 1234, 5678, and 9012\",  # More than 2 campaigns\n",
    "    \"What is the weather today?\",  # Out of domain question\n",
    "]\n",
    "\n",
    "for query in edge_cases:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Invoke the agent and get the final response\n",
    "        result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "        # Extract the last message content\n",
    "        final_message = result[\"messages\"][-1].content\n",
    "        print(f\"Result: {final_message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# TODO: Document your observations below\n",
    "# - How did the agent handle the non-existent campaign?\n",
    "# - What happened with the 3-campaign comparison?\n",
    "# - How did it respond to the out-of-domain question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Comparison: Manual vs LangChain\n",
    "\n",
    "| Aspect | Manual (Lesson 3) | LangChain (Lesson 4) |\n",
    "|--------|-------------------|----------------------|\n",
    "| Lines of code | ~100 for agent loop | ~10 for agent setup |\n",
    "| Error handling | Manual JSON parsing | Built-in |\n",
    "| Tool dispatch | Custom logic | Automatic |\n",
    "| Prompt format | Manual string building | Template-based |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **LangChain Documentation**: https://python.langchain.com/docs/introduction/\n",
    "- **GROQ Console**: https://console.groq.com\n",
    "- **ReAct Paper**: https://arxiv.org/abs/2210.03629\n",
    "- **LangChain Agents Tutorial**: https://python.langchain.com/docs/tutorials/agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
