{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e48baa7",
   "metadata": {},
   "source": [
    "# Lesson 3: Practical LLM Applications\n",
    "\n",
    "This notebook explores three fundamental applications of Large Language Models in professional contexts:\n",
    "\n",
    "1. **Conversational Assistants**: Building context-aware dialogue systems\n",
    "2. **Document Analysis and Information Extraction**: Extracting structured data from unstructured text\n",
    "3. **Report Generation**: Automating the creation of structured reports\n",
    "\n",
    "The notebook is organized in two parts:\n",
    "\n",
    "**Part 1: Direct LLM Integration**\n",
    "Working directly with LLM APIs (Groq and Gemini) to understand core concepts\n",
    "\n",
    "**Part 2: LangChain Agentic Framework**\n",
    "Leveraging LangChain to build more sophisticated applications with agents and tools\n",
    "\n",
    "**Prerequisites:**\n",
    "- Basic Python programming\n",
    "- Understanding of API concepts\n",
    "- Familiarity with LLM fundamentals (covered in Lessons 1-2)\n",
    "\n",
    "**Estimated time:** 90-120 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a52fb9",
   "metadata": {},
   "source": [
    "---\n",
    "## Initial Setup\n",
    "\n",
    "### API Configuration\n",
    "\n",
    "This notebook uses two LLM providers:\n",
    "\n",
    "**1. Groq API** - Fast inference with open-source models\n",
    "- Console: https://console.groq.com\n",
    "- Model: `llama-3.3-70b-versatile`\n",
    "\n",
    "**2. Google Gemini API** - Google's multimodal models\n",
    "- Get API key: https://aistudio.google.com/app/apikey\n",
    "- Model: `gemini-2.0-flash`\n",
    "\n",
    "### How to Get API Keys\n",
    "\n",
    "**Groq:**\n",
    "1. Sign up at https://console.groq.com\n",
    "2. Go to \"API Keys\" in the sidebar\n",
    "3. Click \"Create API Key\"\n",
    "\n",
    "**Gemini:**\n",
    "1. Go to https://aistudio.google.com\n",
    "2. Sign in with your Google account\n",
    "3. Click \"Get API Key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad385913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install --quiet openai google-genai python-dotenv langchain langchain-groq langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c97251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:38.966271Z",
     "start_time": "2025-12-09T16:17:38.551032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys configured: {'groq': True, 'gemini': True}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Read keys from environment\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "\n",
    "print(\"API Keys configured:\", {\"groq\": bool(GROQ_API_KEY), \"gemini\": bool(GEMINI_API_KEY)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ae8130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:40.152363Z",
     "start_time": "2025-12-09T16:17:40.060714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized\n",
      "Gemini client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize clients\n",
    "groq_client = None\n",
    "gemini_client = None\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    groq_client = OpenAI(api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "    print(\"Groq client initialized\")\n",
    "\n",
    "if GEMINI_API_KEY:\n",
    "    gemini_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "    print(\"Gemini client initialized\")\n",
    "\n",
    "if not any([groq_client, gemini_client]):\n",
    "    print(\"Warning: No LLM clients configured. Set GROQ_API_KEY and/or GEMINI_API_KEY.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358aee50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:40.831244Z",
     "start_time": "2025-12-09T16:17:40.785385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default provider: groq\n",
      "LLM wrapper functions ready\n"
     ]
    }
   ],
   "source": [
    "# LLM wrapper functions\n",
    "\n",
    "def call_groq(\n",
    "    prompt: str, \n",
    "    system_prompt: str = None,\n",
    "    temperature: float = 0.0, \n",
    "    max_tokens: int = 1000, \n",
    "    model: str = \"llama-3.3-70b-versatile\"\n",
    ") -> str:\n",
    "    \"\"\"Call Groq API with optional system prompt.\"\"\"\n",
    "    if not groq_client:\n",
    "        return \"Groq client not configured (set GROQ_API_KEY).\"\n",
    "    try:\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        resp = groq_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return resp.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Groq API error: {e}\"\n",
    "\n",
    "\n",
    "def call_gemini(\n",
    "    prompt: str, \n",
    "    system_prompt: str = None,\n",
    "    temperature: float = 0.0, \n",
    "    max_tokens: int = 1000, \n",
    "    model: str = \"gemini-2.0-flash\"\n",
    ") -> str:\n",
    "    \"\"\"Call Gemini API with optional system prompt.\"\"\"\n",
    "    if not gemini_client:\n",
    "        return \"Gemini client not configured (set GEMINI_API_KEY).\"\n",
    "    try:\n",
    "        full_prompt = prompt\n",
    "        if system_prompt:\n",
    "            full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
    "        \n",
    "        response = gemini_client.models.generate_content(\n",
    "            contents=full_prompt, \n",
    "            model=model, \n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=temperature, \n",
    "                max_output_tokens=max_tokens\n",
    "            )\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Gemini API error: {e}\"\n",
    "\n",
    "\n",
    "def call_llm(\n",
    "    prompt: str, \n",
    "    provider: str = \"groq\", \n",
    "    system_prompt: str = None,\n",
    "    temperature: float = 0.0, \n",
    "    max_tokens: int = 1000, \n",
    "    model: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Unified wrapper for LLM calls.\"\"\"\n",
    "    provider = provider.lower()\n",
    "    if provider == \"groq\":\n",
    "        return call_groq(\n",
    "            prompt, \n",
    "            system_prompt=system_prompt,\n",
    "            temperature=temperature, \n",
    "            max_tokens=max_tokens, \n",
    "            model=(model or \"llama-3.3-70b-versatile\")\n",
    "        )\n",
    "    if provider == \"gemini\":\n",
    "        return call_gemini(\n",
    "            prompt, \n",
    "            system_prompt=system_prompt,\n",
    "            temperature=temperature, \n",
    "            max_tokens=max_tokens, \n",
    "            model=(model or \"gemini-2.0-flash\")\n",
    "        )\n",
    "    return f\"Unknown provider: {provider}. Use 'groq' or 'gemini'.\"\n",
    "\n",
    "\n",
    "# Select default provider\n",
    "PROVIDER = \"groq\"  # Change to \"gemini\" if preferred\n",
    "print(f\"Default provider: {PROVIDER}\")\n",
    "print(\"LLM wrapper functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d1112a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:41.865197Z",
     "start_time": "2025-12-09T16:17:41.337724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM connection...\n",
      "Response: 4\n"
     ]
    }
   ],
   "source": [
    "# Quick connectivity test\n",
    "test_prompt = \"What is 2 + 2? Answer with just the number.\"\n",
    "print(\"Testing LLM connection...\")\n",
    "result = call_llm(test_prompt, provider=PROVIDER)\n",
    "print(f\"Response: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9dd57",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Direct LLM Integration\n",
    "\n",
    "In this section, we explore the three applications using direct LLM API calls. This approach provides full control over the interaction and helps understand the underlying mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06bec5",
   "metadata": {},
   "source": [
    "---\n",
    "## Application 1: Conversational Assistants\n",
    "\n",
    "Conversational assistants are systems that maintain context across multiple exchanges, providing coherent and contextually relevant responses.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Conversation History**: Maintaining state across turns\n",
    "- **System Prompts**: Defining assistant behavior and personality\n",
    "- **Context Window Management**: Handling token limits\n",
    "- **Turn-taking**: Managing user/assistant message flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc23e22",
   "metadata": {},
   "source": [
    "### 1.1 Basic Conversational Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4196125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:43.832768Z",
     "start_time": "2025-12-09T16:17:43.821413Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConversationalAssistant:\n",
    "    \"\"\"\n",
    "    A conversational assistant that maintains context across multiple exchanges.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        system_prompt: str,\n",
    "        provider: str = \"groq\",\n",
    "        max_history: int = 10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the conversational assistant.\n",
    "        \n",
    "        Args:\n",
    "            system_prompt: Defines the assistant's behavior and role\n",
    "            provider: LLM provider to use ('groq' or 'gemini')\n",
    "            max_history: Maximum number of exchanges to maintain\n",
    "        \"\"\"\n",
    "        self.system_prompt = system_prompt\n",
    "        self.provider = provider\n",
    "        self.max_history = max_history\n",
    "        self.conversation_history: List[Dict[str, str]] = []\n",
    "    \n",
    "    def _build_prompt(self, user_message: str) -> str:\n",
    "        \"\"\"Build the full prompt including conversation history.\"\"\"\n",
    "        history_text = \"\"\n",
    "        for exchange in self.conversation_history[-self.max_history:]:\n",
    "            history_text += f\"User: {exchange['user']}\\n\"\n",
    "            history_text += f\"Assistant: {exchange['assistant']}\\n\\n\"\n",
    "        \n",
    "        full_prompt = f\"\"\"Previous conversation:\n",
    "{history_text}\n",
    "\n",
    "Current user message: {user_message}\n",
    "\n",
    "Provide a helpful response based on the conversation context.\"\"\"\n",
    "        \n",
    "        return full_prompt\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a user message and return the assistant's response.\n",
    "        \n",
    "        Args:\n",
    "            user_message: The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            The assistant's response\n",
    "        \"\"\"\n",
    "        prompt = self._build_prompt(user_message)\n",
    "        \n",
    "        response = call_llm(\n",
    "            prompt=prompt,\n",
    "            provider=self.provider,\n",
    "            system_prompt=self.system_prompt,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Store in history\n",
    "        self.conversation_history.append({\n",
    "            \"user\": user_message,\n",
    "            \"assistant\": response\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"Conversation history cleared.\")\n",
    "    \n",
    "    def get_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Return the conversation history.\"\"\"\n",
    "        return self.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e93fe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:47.127164Z",
     "start_time": "2025-12-09T16:17:44.477316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CAMPAIGN ANALYSIS ASSISTANT DEMO\n",
      "============================================================\n",
      "\n",
      "User: I have a campaign with 5.2 million impressions and 48% reach. Is this good performance?\n",
      "\n",
      "Assistant: To assess the performance of your campaign, we need to consider a few more metrics. With 5.2 million impressions and a 48% reach, it seems like you've achieved a significant amount of exposure. However, to determine if this is \"good\" performance, I'd like to know more about your campaign goals and target audience.\n",
      "\n",
      "Can you please provide the following information:\n",
      "1. What is the frequency (average number of times a user has seen your ad)?\n",
      "2. What is the campaign's click-through rate (CTR) or conversion rate?\n",
      "3. Who is your target audience, and what is the total available market (TAM) or the estimated population size you're trying to reach?\n",
      "4. What is the campaign's objective (awareness, consideration, conversion, etc.)?\n",
      "\n",
      "With this additional context, I can provide a more informed analysis of your campaign's performance.\n",
      "\n",
      "============================================================\n",
      "\n",
      "User: The target was adults 25-54. How does that change your assessment?\n",
      "\n",
      "Assistant: With the target audience being adults 25-54, we can start to piece together a more comprehensive understanding of your campaign's performance.\n",
      "\n",
      "Assuming the total available market (TAM) for adults 25-54 in your region is approximately 100 million people (please note that this is an assumption, as I don't have specific data on your region or country), a 48% reach would translate to around 48 million unique individuals being exposed to your campaign.\n",
      "\n",
      "However, to further assess the campaign's effectiveness, I would still like to know the following metrics:\n",
      "\n",
      "1. Frequency (average number of times a user has seen your ad): This will help us understand if the campaign is achieving sufficient exposure without overwhelming the audience.\n",
      "2. Click-through rate (CTR) or conversion rate: These metrics will provide insight into how engaging the ad is and whether it's driving the desired actions.\n",
      "3. Campaign objective: Is the goal to raise awareness, drive consideration, or generate conversions? This context will help me evaluate the campaign's performance against its intended purpose.\n",
      "\n",
      "If you can provide these additional details, I can offer a more informed analysis of your campaign's performance and suggest potential areas for optimization.\n",
      "\n",
      "============================================================\n",
      "\n",
      "User: What frequency would you recommend for this target?\n",
      "\n",
      "Assistant: Based on the target audience of adults 25-54, I would recommend a frequency of 3-5 exposures per user for an awareness-driven campaign. This range allows for sufficient exposure to the ad message without overwhelming the audience, which can lead to decreased engagement and increased costs.\n",
      "\n",
      "For a consideration or conversion-driven campaign, a slightly lower frequency of 2-4 exposures per user may be more effective, as it can help to avoid ad fatigue and maintain user interest.\n",
      "\n",
      "However, it's essential to note that the ideal frequency can vary depending on the campaign's specific objectives, ad creative, and media channels. If you're using a mix of online and offline channels, you may need to adjust the frequency accordingly to avoid over-exposure.\n",
      "\n",
      "To provide a more tailored recommendation, could you please share the campaign's objective (awareness, consideration, conversion, etc.) and the media channels being used (social media, TV, radio, etc.)? Additionally, do you have any existing frequency data or benchmarks from previous campaigns that I can reference?\n"
     ]
    }
   ],
   "source": [
    "# Example: Campaign Analysis Assistant\n",
    "\n",
    "CAMPAIGN_ASSISTANT_PROMPT = \"\"\"You are a professional advertising campaign analyst.\n",
    "Your role is to help marketing professionals understand and optimize their campaigns.\n",
    "\n",
    "Guidelines:\n",
    "- Provide data-driven insights when possible\n",
    "- Ask clarifying questions when information is incomplete\n",
    "- Use industry-standard terminology\n",
    "- Be concise but thorough\n",
    "- When you don't have specific data, clearly state your assumptions\"\"\"\n",
    "\n",
    "# Initialize the assistant\n",
    "campaign_assistant = ConversationalAssistant(\n",
    "    system_prompt=CAMPAIGN_ASSISTANT_PROMPT,\n",
    "    provider=PROVIDER\n",
    ")\n",
    "\n",
    "# Simulate a conversation\n",
    "print(\"=\" * 60)\n",
    "print(\"CAMPAIGN ANALYSIS ASSISTANT DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First exchange\n",
    "response1 = campaign_assistant.chat(\n",
    "    \"I have a campaign with 5.2 million impressions and 48% reach. Is this good performance?\"\n",
    ")\n",
    "print(f\"\\nUser: I have a campaign with 5.2 million impressions and 48% reach. Is this good performance?\")\n",
    "print(f\"\\nAssistant: {response1}\")\n",
    "\n",
    "# Second exchange (referencing previous context)\n",
    "response2 = campaign_assistant.chat(\n",
    "    \"The target was adults 25-54. How does that change your assessment?\"\n",
    ")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\\nUser: The target was adults 25-54. How does that change your assessment?\")\n",
    "print(f\"\\nAssistant: {response2}\")\n",
    "\n",
    "# Third exchange\n",
    "response3 = campaign_assistant.chat(\n",
    "    \"What frequency would you recommend for this target?\"\n",
    ")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\\nUser: What frequency would you recommend for this target?\")\n",
    "print(f\"\\nAssistant: {response3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9e111",
   "metadata": {},
   "source": [
    "### 1.2 Specialized Domain Assistant\n",
    "\n",
    "The following example demonstrates a more specialized assistant with domain-specific knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1cab50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:47.975964Z",
     "start_time": "2025-12-09T16:17:47.128860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TV METRICS EXPERT DEMO\n",
      "============================================================\n",
      "\n",
      "User: I need to calculate the GRP for a campaign with 45% reach and 3.5 average frequency.\n",
      "\n",
      "Assistant: To calculate the Gross Rating Points (GRP) for your campaign, we can use the following formula:\n",
      "\n",
      "GRP = Reach (%) x Average Frequency\n",
      "\n",
      "Given the data you provided:\n",
      "Reach (%) = 45%\n",
      "Average Frequency = 3.5\n",
      "\n",
      "Plugging in the numbers, we get:\n",
      "GRP = 45 x 3.5\n",
      "GRP = 157.5\n",
      "\n",
      "So, the GRP for your campaign is 157.5.\n",
      "\n",
      "In practical terms, this means that your campaign has delivered 157.5% of the total potential audience, with the average person in the target audience seeing your ad 3.5 times. This is a relatively high GRP, indicating a strong campaign presence.\n",
      "\n",
      "For context, industry benchmarks for GRP vary by campaign objective and target audience, but a GRP of 100-200 is often considered a good starting point for awareness-driven campaigns. However, the ideal GRP will depend on your specific campaign goals and target audience.\n",
      "\n",
      "Do you have any other questions about your campaign's performance or would you like to explore other metrics, such as CPM or reach and frequency distribution?\n"
     ]
    }
   ],
   "source": [
    "# Specialized prompt for TV advertising metrics\n",
    "\n",
    "TV_METRICS_PROMPT = \"\"\"You are an expert in television advertising metrics and measurement.\n",
    "\n",
    "Your knowledge includes:\n",
    "- Reach and Frequency calculations\n",
    "- GRP (Gross Rating Points) analysis\n",
    "- CPM and cost efficiency metrics\n",
    "- Audience measurement methodologies\n",
    "- Campaign optimization strategies\n",
    "\n",
    "When answering questions:\n",
    "1. Use precise industry terminology\n",
    "2. Provide formulas when relevant\n",
    "3. Explain the practical implications of metrics\n",
    "4. Reference industry benchmarks when appropriate\n",
    "\n",
    "If the user provides data, perform calculations and explain each step.\"\"\"\n",
    "\n",
    "metrics_assistant = ConversationalAssistant(\n",
    "    system_prompt=TV_METRICS_PROMPT,\n",
    "    provider=PROVIDER\n",
    ")\n",
    "\n",
    "# Demonstrate specialized knowledge\n",
    "print(\"=\" * 60)\n",
    "print(\"TV METRICS EXPERT DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = metrics_assistant.chat(\n",
    "    \"I need to calculate the GRP for a campaign with 45% reach and 3.5 average frequency.\"\n",
    ")\n",
    "print(f\"\\nUser: I need to calculate the GRP for a campaign with 45% reach and 3.5 average frequency.\")\n",
    "print(f\"\\nAssistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822a124",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Build a Custom Conversational Assistant\n",
    "\n",
    "Create a conversational assistant for a specific use case of your choice.\n",
    "\n",
    "Requirements:\n",
    "- Define a clear system prompt with role and guidelines\n",
    "- Test with at least 3 conversation turns\n",
    "- Demonstrate context retention across turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f2ccd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:47.997288Z",
     "start_time": "2025-12-09T16:17:47.984646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.1: Your solution here\n",
    "\n",
    "# TODO: Define your system prompt\n",
    "CUSTOM_ASSISTANT_PROMPT = \"\"\"\n",
    "# Define your assistant's role and guidelines here\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Initialize the assistant\n",
    "# custom_assistant = ConversationalAssistant(...)\n",
    "\n",
    "# TODO: Test with multiple conversation turns\n",
    "# response1 = custom_assistant.chat(\"...\")\n",
    "# response2 = custom_assistant.chat(\"...\")\n",
    "# response3 = custom_assistant.chat(\"...\")\n",
    "\n",
    "# See solutions.py for reference implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b539b2d",
   "metadata": {},
   "source": [
    "---\n",
    "## Application 2: Document Analysis and Information Extraction\n",
    "\n",
    "Information extraction involves identifying and extracting structured data from unstructured text documents.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Named Entity Recognition**: Identifying entities (dates, amounts, names)\n",
    "- **Structured Output**: Converting text to JSON/structured formats\n",
    "- **Schema Validation**: Ensuring extracted data matches expected format\n",
    "- **Multi-document Analysis**: Processing multiple documents consistently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4175fd",
   "metadata": {},
   "source": [
    "### 2.1 Basic Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d300f13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:49.081848Z",
     "start_time": "2025-12-09T16:17:49.070162Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_campaign_info(document: str, provider: str = PROVIDER) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract structured campaign information from a text document.\n",
    "    \n",
    "    Args:\n",
    "        document: The text document to analyze\n",
    "        provider: LLM provider to use\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing extracted information\n",
    "    \"\"\"\n",
    "    extraction_prompt = f\"\"\"Analyze the following document and extract campaign information.\n",
    "\n",
    "DOCUMENT:\n",
    "{document}\n",
    "\n",
    "Extract the following fields if present:\n",
    "- campaign_name: Name or title of the campaign\n",
    "- start_date: Campaign start date (format: YYYY-MM-DD)\n",
    "- end_date: Campaign end date (format: YYYY-MM-DD)\n",
    "- budget: Campaign budget (numeric value)\n",
    "- currency: Currency of the budget\n",
    "- target_audience: Description of target audience\n",
    "- channels: List of advertising channels used\n",
    "- objectives: Campaign objectives or goals\n",
    "- kpis: Key performance indicators mentioned\n",
    "\n",
    "Return ONLY a valid JSON object with these fields.\n",
    "Use null for fields that cannot be determined from the document.\n",
    "Do not include any text outside the JSON object.\"\"\"\n",
    "\n",
    "    response = call_llm(\n",
    "        prompt=extraction_prompt,\n",
    "        provider=provider,\n",
    "        temperature=0.0,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Parse JSON from response\n",
    "    try:\n",
    "        # Try to extract JSON from the response\n",
    "        json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "        return {\"error\": \"Could not parse JSON from response\", \"raw_response\": response}\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"error\": f\"JSON parse error: {e}\", \"raw_response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a07503a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:50.098782Z",
     "start_time": "2025-12-09T16:17:49.629214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DOCUMENT ANALYSIS DEMO\n",
      "============================================================\n",
      "\n",
      "Extracting information from campaign brief...\n",
      "\n",
      "Extracted Information:\n",
      "{\n",
      "  \"campaign_name\": \"Autumn 2024 Brand Awareness\",\n",
      "  \"start_date\": \"2024-09-15\",\n",
      "  \"end_date\": \"2024-11-30\",\n",
      "  \"budget\": 250000,\n",
      "  \"currency\": \"EUR\",\n",
      "  \"target_audience\": \"Adults aged 25-45, primary focus on professionals in urban areas. Secondary audience includes tech-savvy young adults 18-24.\",\n",
      "  \"channels\": [\n",
      "    \"National TV\",\n",
      "    \"Digital Display\",\n",
      "    \"Social Media\",\n",
      "    \"Out-of-Home\"\n",
      "  ],\n",
      "  \"objectives\": [\n",
      "    \"Increase brand awareness by 15% among target audience\",\n",
      "    \"Drive 50,000 qualified website visits\",\n",
      "    \"Achieve minimum reach of 60% in primary target\"\n",
      "  ],\n",
      "  \"kpis\": [\n",
      "    \"Brand awareness lift\",\n",
      "    \"Website traffic from campaign sources\",\n",
      "    \"Social media engagement rate\",\n",
      "    \"TV reach and frequency metrics\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example document for extraction\n",
    "sample_document = \"\"\"\n",
    "CAMPAIGN BRIEF: Autumn 2024 Brand Awareness\n",
    "\n",
    "Client: TechCorp Italia\n",
    "Campaign Period: September 15, 2024 - November 30, 2024\n",
    "Total Budget: EUR 250,000\n",
    "\n",
    "Target Audience:\n",
    "Adults aged 25-45, primary focus on professionals in urban areas.\n",
    "Secondary audience includes tech-savvy young adults 18-24.\n",
    "\n",
    "Media Channels:\n",
    "- National TV (RAI, Mediaset)\n",
    "- Digital Display (programmatic)\n",
    "- Social Media (Instagram, LinkedIn)\n",
    "- Out-of-Home in Milan and Rome\n",
    "\n",
    "Campaign Objectives:\n",
    "1. Increase brand awareness by 15% among target audience\n",
    "2. Drive 50,000 qualified website visits\n",
    "3. Achieve minimum reach of 60% in primary target\n",
    "\n",
    "Key Performance Indicators:\n",
    "- Brand awareness lift (pre/post survey)\n",
    "- Website traffic from campaign sources\n",
    "- Social media engagement rate\n",
    "- TV reach and frequency metrics\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DOCUMENT ANALYSIS DEMO\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nExtracting information from campaign brief...\")\n",
    "\n",
    "extracted_info = extract_campaign_info(sample_document)\n",
    "print(\"\\nExtracted Information:\")\n",
    "print(json.dumps(extracted_info, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8afb72",
   "metadata": {},
   "source": [
    "### 2.2 Multi-Field Extraction with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833c6f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:50.915063Z",
     "start_time": "2025-12-09T16:17:50.904625Z"
    }
   },
   "outputs": [],
   "source": [
    "class DocumentExtractor:\n",
    "    \"\"\"\n",
    "    A document extractor with schema validation and error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, schema: Dict[str, Any], provider: str = \"groq\"):\n",
    "        \"\"\"\n",
    "        Initialize the extractor with a schema.\n",
    "        \n",
    "        Args:\n",
    "            schema: Dictionary defining expected fields and their types\n",
    "            provider: LLM provider to use\n",
    "        \"\"\"\n",
    "        self.schema = schema\n",
    "        self.provider = provider\n",
    "    \n",
    "    def _build_schema_description(self) -> str:\n",
    "        \"\"\"Build a description of the schema for the prompt.\"\"\"\n",
    "        lines = []\n",
    "        for field, config in self.schema.items():\n",
    "            field_type = config.get(\"type\", \"string\")\n",
    "            description = config.get(\"description\", \"\")\n",
    "            required = config.get(\"required\", False)\n",
    "            req_marker = \"(required)\" if required else \"(optional)\"\n",
    "            lines.append(f\"- {field} [{field_type}] {req_marker}: {description}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def extract(self, document: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract information from a document according to the schema.\n",
    "        \n",
    "        Args:\n",
    "            document: The text document to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing extracted and validated information\n",
    "        \"\"\"\n",
    "        schema_desc = self._build_schema_description()\n",
    "        \n",
    "        prompt = f\"\"\"Analyze the following document and extract information according to the schema.\n",
    "\n",
    "DOCUMENT:\n",
    "{document}\n",
    "\n",
    "EXTRACTION SCHEMA:\n",
    "{schema_desc}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Extract values for each field based on the document content\n",
    "2. Use null for fields that cannot be determined\n",
    "3. Ensure data types match the schema specifications\n",
    "4. For list fields, provide an array of values\n",
    "5. For numeric fields, extract only the number (without currency symbols)\n",
    "\n",
    "Return ONLY a valid JSON object matching the schema. No additional text.\"\"\"\n",
    "\n",
    "        response = call_llm(\n",
    "            prompt=prompt,\n",
    "            provider=self.provider,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        # Parse and validate\n",
    "        try:\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                extracted = json.loads(json_match.group())\n",
    "                validation_result = self._validate(extracted)\n",
    "                return {\n",
    "                    \"data\": extracted,\n",
    "                    \"validation\": validation_result\n",
    "                }\n",
    "            return {\"error\": \"Could not parse JSON\", \"raw_response\": response}\n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\"error\": f\"JSON parse error: {e}\", \"raw_response\": response}\n",
    "    \n",
    "    def _validate(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Validate extracted data against the schema.\"\"\"\n",
    "        errors = []\n",
    "        warnings = []\n",
    "        \n",
    "        for field, config in self.schema.items():\n",
    "            required = config.get(\"required\", False)\n",
    "            field_type = config.get(\"type\", \"string\")\n",
    "            \n",
    "            if field not in data or data[field] is None:\n",
    "                if required:\n",
    "                    errors.append(f\"Required field '{field}' is missing or null\")\n",
    "                continue\n",
    "            \n",
    "            value = data[field]\n",
    "            \n",
    "            # Type validation\n",
    "            if field_type == \"number\" and not isinstance(value, (int, float)):\n",
    "                errors.append(f\"Field '{field}' should be a number, got {type(value).__name__}\")\n",
    "            elif field_type == \"list\" and not isinstance(value, list):\n",
    "                errors.append(f\"Field '{field}' should be a list, got {type(value).__name__}\")\n",
    "            elif field_type == \"string\" and not isinstance(value, str):\n",
    "                warnings.append(f\"Field '{field}' converted to string\")\n",
    "        \n",
    "        return {\n",
    "            \"is_valid\": len(errors) == 0,\n",
    "            \"errors\": errors,\n",
    "            \"warnings\": warnings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da7a563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:51.977325Z",
     "start_time": "2025-12-09T16:17:51.547691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCHEMA-BASED EXTRACTION DEMO\n",
      "============================================================\n",
      "\n",
      "Extraction Result:\n",
      "{\n",
      "  \"data\": {\n",
      "    \"campaign_name\": \"Autumn 2024 Brand Awareness\",\n",
      "    \"client\": \"TechCorp Italia\",\n",
      "    \"budget_amount\": 250000,\n",
      "    \"budget_currency\": \"EUR\",\n",
      "    \"target_age_min\": 18,\n",
      "    \"target_age_max\": 45,\n",
      "    \"channels\": [\n",
      "      \"National TV\",\n",
      "      \"Digital Display\",\n",
      "      \"Social Media\",\n",
      "      \"Out-of-Home\"\n",
      "    ],\n",
      "    \"objectives\": [\n",
      "      \"Increase brand awareness by 15% among target audience\",\n",
      "      \"Drive 50,000 qualified website visits\",\n",
      "      \"Achieve minimum reach of 60% in primary target\"\n",
      "    ]\n",
      "  },\n",
      "  \"validation\": {\n",
      "    \"is_valid\": true,\n",
      "    \"errors\": [],\n",
      "    \"warnings\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define extraction schema\n",
    "campaign_schema = {\n",
    "    \"campaign_name\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Name or title of the campaign\",\n",
    "        \"required\": True\n",
    "    },\n",
    "    \"client\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Client or brand name\",\n",
    "        \"required\": True\n",
    "    },\n",
    "    \"budget_amount\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"Total budget as a numeric value\",\n",
    "        \"required\": True\n",
    "    },\n",
    "    \"budget_currency\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Currency code (EUR, USD, etc.)\",\n",
    "        \"required\": False\n",
    "    },\n",
    "    \"target_age_min\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"Minimum age of target audience\",\n",
    "        \"required\": False\n",
    "    },\n",
    "    \"target_age_max\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"Maximum age of target audience\",\n",
    "        \"required\": False\n",
    "    },\n",
    "    \"channels\": {\n",
    "        \"type\": \"list\",\n",
    "        \"description\": \"List of advertising channels\",\n",
    "        \"required\": False\n",
    "    },\n",
    "    \"objectives\": {\n",
    "        \"type\": \"list\",\n",
    "        \"description\": \"List of campaign objectives\",\n",
    "        \"required\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create extractor and process document\n",
    "extractor = DocumentExtractor(schema=campaign_schema, provider=PROVIDER)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SCHEMA-BASED EXTRACTION DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = extractor.extract(sample_document)\n",
    "print(\"\\nExtraction Result:\")\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3612a9a",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Create a Custom Document Extractor\n",
    "\n",
    "Create an extractor for a different document type (e.g., invoice, contract, report).\n",
    "\n",
    "Requirements:\n",
    "- Define a custom schema with at least 6 fields\n",
    "- Include different data types (string, number, list)\n",
    "- Test with a sample document\n",
    "- Verify validation works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95ed9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:53.274381Z",
     "start_time": "2025-12-09T16:17:53.249055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.1: Your solution here\n",
    "\n",
    "# TODO: Define your custom schema\n",
    "custom_schema = {\n",
    "    # Add your fields here\n",
    "}\n",
    "\n",
    "# TODO: Create sample document text\n",
    "sample_custom_document = \"\"\"\n",
    "# Your sample document here\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create extractor and test\n",
    "# custom_extractor = DocumentExtractor(schema=custom_schema, provider=PROVIDER)\n",
    "# result = custom_extractor.extract(sample_custom_document)\n",
    "# print(json.dumps(result, indent=2))\n",
    "\n",
    "# See solutions.py for reference implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d6846",
   "metadata": {},
   "source": [
    "---\n",
    "## Application 3: Report Generation\n",
    "\n",
    "Automated report generation involves creating structured, professional documents from data and analysis results.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Template-based Generation**: Using templates for consistent formatting\n",
    "- **Data Integration**: Incorporating numerical data and metrics\n",
    "- **Narrative Generation**: Creating explanatory text from data\n",
    "- **Multi-section Documents**: Organizing content logically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1a90c",
   "metadata": {},
   "source": [
    "### 3.1 Basic Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38f6c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:55.050952Z",
     "start_time": "2025-12-09T16:17:55.037896Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    \"\"\"\n",
    "    Generates structured reports from data using LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, provider: str = \"groq\"):\n",
    "        self.provider = provider\n",
    "    \n",
    "    def generate_executive_summary(\n",
    "        self, \n",
    "        campaign_data: Dict[str, Any],\n",
    "        include_recommendations: bool = True\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate an executive summary for a campaign.\n",
    "        \n",
    "        Args:\n",
    "            campaign_data: Dictionary containing campaign metrics\n",
    "            include_recommendations: Whether to include recommendations\n",
    "            \n",
    "        Returns:\n",
    "            Generated executive summary text\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Generate a professional executive summary for the following campaign data.\n",
    "\n",
    "CAMPAIGN DATA:\n",
    "{json.dumps(campaign_data, indent=2)}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Start with a brief overview (2-3 sentences)\n",
    "2. Highlight key performance metrics\n",
    "3. Compare against targets if provided\n",
    "4. {\"Include 2-3 actionable recommendations\" if include_recommendations else \"Do not include recommendations\"}\n",
    "5. Use professional business language\n",
    "6. Keep the summary concise (maximum 300 words)\n",
    "\n",
    "Write the executive summary:\"\"\"\n",
    "\n",
    "        return call_llm(\n",
    "            prompt=prompt,\n",
    "            provider=self.provider,\n",
    "            temperature=0.3,\n",
    "            max_tokens=500\n",
    "        )\n",
    "    \n",
    "    def generate_detailed_report(\n",
    "        self,\n",
    "        campaign_data: Dict[str, Any],\n",
    "        sections: List[str] = None\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Generate a detailed multi-section report.\n",
    "        \n",
    "        Args:\n",
    "            campaign_data: Dictionary containing campaign metrics\n",
    "            sections: List of section names to include\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping section names to generated content\n",
    "        \"\"\"\n",
    "        if sections is None:\n",
    "            sections = [\n",
    "                \"Overview\",\n",
    "                \"Performance Analysis\",\n",
    "                \"Audience Insights\",\n",
    "                \"Recommendations\"\n",
    "            ]\n",
    "        \n",
    "        report = {}\n",
    "        \n",
    "        for section in sections:\n",
    "            prompt = f\"\"\"Generate the \"{section}\" section for a campaign performance report.\n",
    "\n",
    "CAMPAIGN DATA:\n",
    "{json.dumps(campaign_data, indent=2)}\n",
    "\n",
    "SECTION: {section}\n",
    "\n",
    "GUIDELINES:\n",
    "- Write 2-4 paragraphs appropriate for this section\n",
    "- Use data from the campaign metrics\n",
    "- Maintain professional tone\n",
    "- Be specific with numbers and percentages\n",
    "\n",
    "Generate the {section} section:\"\"\"\n",
    "\n",
    "            content = call_llm(\n",
    "                prompt=prompt,\n",
    "                provider=self.provider,\n",
    "                temperature=0.3,\n",
    "                max_tokens=400\n",
    "            )\n",
    "            report[section] = content\n",
    "        \n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b1e546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:17:57.135772Z",
     "start_time": "2025-12-09T16:17:55.825131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REPORT GENERATION DEMO\n",
      "============================================================\n",
      "\n",
      "--- EXECUTIVE SUMMARY ---\n",
      "\n",
      "The Q4 2024 Brand Launch campaign for TechCorp Italia was a strategic initiative aimed at increasing brand awareness and reach among the target audience. The campaign, which ran from October 1, 2024, to December 15, 2024, had a planned budget of €200,000, with a total spend of €187,500. Key performance metrics indicate a successful campaign, with a reach percentage of 52.3%, exceeding the target of 50.0%.\n",
      "\n",
      "Notable highlights include an impressive frequency of 4.2, 6,100,000 impressions, and a GRP of 219.7. The campaign's reach by age group was also significant, with 58.2% of the 25-34 age group and 49.1% of the 35-44 age group being reached. Channel-wise, TV accounted for 60% of the spend, delivering a reach of 45.2%, while digital and out-of-home (OOH) channels contributed 38.5% and 22.1% reach, respectively.\n",
      "\n",
      "To further optimize future campaigns, we recommend the following: (1) allocating a larger budget to digital channels to capitalize on their high reach and engagement potential, (2) exploring targeted OOH placements to increase reach and frequency among the primary target audience, and (3) conducting a thorough analysis of the campaign's return on investment (ROI) to inform future budget allocation decisions. By implementing these strategies, TechCorp Italia can continue to enhance its brand presence and drive business growth. Overall, the Q4 2024 Brand Launch campaign demonstrated a strong performance, and with data-driven insights, future campaigns can be even more effective.\n"
     ]
    }
   ],
   "source": [
    "# Sample campaign data for report generation\n",
    "campaign_metrics = {\n",
    "    \"campaign_name\": \"Q4 2024 Brand Launch\",\n",
    "    \"client\": \"TechCorp Italia\",\n",
    "    \"period\": {\n",
    "        \"start\": \"2024-10-01\",\n",
    "        \"end\": \"2024-12-15\"\n",
    "    },\n",
    "    \"budget\": {\n",
    "        \"planned\": 200000,\n",
    "        \"spent\": 187500,\n",
    "        \"currency\": \"EUR\"\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"reach_percentage\": 52.3,\n",
    "        \"reach_target\": 50.0,\n",
    "        \"frequency\": 4.2,\n",
    "        \"impressions\": 6100000,\n",
    "        \"grp\": 219.7\n",
    "    },\n",
    "    \"audience\": {\n",
    "        \"primary_target\": \"Adults 25-44\",\n",
    "        \"reach_by_age\": {\n",
    "            \"25-34\": 58.2,\n",
    "            \"35-44\": 49.1\n",
    "        }\n",
    "    },\n",
    "    \"channels\": {\n",
    "        \"tv\": {\"spend_pct\": 60, \"reach\": 45.2},\n",
    "        \"digital\": {\"spend_pct\": 30, \"reach\": 38.5},\n",
    "        \"ooh\": {\"spend_pct\": 10, \"reach\": 22.1}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate reports\n",
    "report_generator = ReportGenerator(provider=PROVIDER)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REPORT GENERATION DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Executive Summary\n",
    "print(\"\\n--- EXECUTIVE SUMMARY ---\\n\")\n",
    "summary = report_generator.generate_executive_summary(campaign_metrics)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d047ff2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:18:01.721159Z",
     "start_time": "2025-12-09T16:17:57.146905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED REPORT SECTIONS\n",
      "============================================================\n",
      "\n",
      "--- OVERVIEW ---\n",
      "\n",
      "The Q4 2024 Brand Launch campaign for TechCorp Italia was a comprehensive marketing effort that took place from October 1, 2024, to December 15, 2024. With a planned budget of €200,000, the campaign aimed to effectively reach and engage the target audience, primarily Adults 25-44. The actual spend for the campaign was €187,500, which is 93.75% of the planned budget, indicating efficient budget management.\n",
      "\n",
      "In terms of performance, the campaign achieved a notable reach percentage of 52.3%, surpassing the target of 50.0%. This translates to approximately 6,100,000 impressions, with a frequency of 4.2. The Gross Rating Point (GRP) for the campaign was 219.7, demonstrating a significant impact on the target audience. The campaign's reach was particularly strong among the 25-34 age group, with 58.2% of this demographic being reached, and 49.1% for the 35-44 age group. These numbers indicate that the campaign was successful in connecting with the primary target audience.\n",
      "\n",
      "The campaign's media channels played a crucial role in achieving these results. Television (TV) was the primary channel, accounting for 60% of the spend and reaching 45.2% of the target audience. Digital channels contributed 30% of the spend and achieved a reach of 38.5%, while Out-of-Home (OOH) channels made up 10% of the spend and reached 22.1% of the audience. This multi-channel approach allowed the campaign to effectively reach a broad audience and maximize its impact. By allocating the budget across these channels, the campaign was able to optimize its reach and frequency, ultimately driving strong performance metrics.\n",
      "\n",
      "Overall, the Q4 2024 Brand Launch campaign for TechCorp Italia demonstrated a strong performance, with notable reach and impression numbers. The campaign's ability to exceed its reach target\n",
      "\n",
      "\n",
      "--- PERFORMANCE ANALYSIS ---\n",
      "\n",
      "The Q4 2024 Brand Launch campaign for TechCorp Italia has demonstrated a strong performance across various metrics. Notably, the campaign achieved a reach percentage of 52.3%, surpassing the target of 50.0%. This indicates that the campaign effectively reached a significant portion of the intended audience, with over 6,100,000 impressions delivered throughout the period. The frequency of 4.2 suggests that the target audience was exposed to the campaign's messaging multiple times, potentially reinforcing brand awareness and recall.\n",
      "\n",
      "A closer examination of the audience demographics reveals that the primary target of Adults 25-44 was successfully reached, with 58.2% of the 25-34 age group and 49.1% of the 35-44 age group being exposed to the campaign. This alignment with the target audience is a testament to the campaign's strategic planning and execution. Furthermore, the campaign's Gross Rating Point (GRP) of 219.7 indicates a high level of campaign visibility and impact, suggesting that the messaging was effectively communicated to the target audience.\n",
      "\n",
      "In terms of channel performance, the campaign's allocation of budget across TV, digital, and Out-of-Home (OOH) channels appears to have been effective. TV emerged as the dominant channel, accounting for 60% of the spend and delivering a reach of 45.2%. Digital channels, which accounted for 30% of the spend, achieved a reach of 38.5%, while OOH channels, with a 10% spend, reached 22.1% of the audience. These findings suggest that the campaign's channel mix was well-optimized, allowing for a balanced reach across different platforms and audience segments.\n",
      "\n",
      "The campaign's budget management also warrants attention, with a total spend of €187,500, which is approximately 6.25% under the planned budget of €200,000. This underspend may indicate opportunities for further optimization or reallocation of resources in future campaigns.\n",
      "\n",
      "\n",
      "--- RECOMMENDATIONS ---\n",
      "\n",
      "Based on the performance data from the Q4 2024 Brand Launch campaign for TechCorp Italia, several key recommendations can be made to optimize future campaign efforts. Firstly, the campaign's reach percentage of 52.3% exceeded the target of 50.0%, indicating a successful brand launch. The frequency of 4.2 and total impressions of 6,100,000 further underscore the campaign's effectiveness in reaching the target audience. To build on this success, it is recommended that future campaigns maintain a similar media mix, with a focus on TV and digital channels, which accounted for 60% and 30% of spend, respectively, and delivered reach percentages of 45.2% and 38.5%.\n",
      "\n",
      "The audience data also provides valuable insights for future campaign optimization. The primary target audience of Adults 25-44 was effectively reached, with 58.2% of the 25-34 age group and 49.1% of the 35-44 age group being exposed to the campaign. To further refine the targeting strategy, it is recommended that future campaigns allocate a slightly higher proportion of spend to digital channels, which tend to offer more precise targeting capabilities. This could help to increase the reach percentage among the 35-44 age group, which was slightly lower than the 25-34 age group. Additionally, considering the strong performance of TV, with a reach percentage of 45.2%, it may be beneficial to explore opportunities to increase spend in this channel, potentially by allocating a portion of the 10% currently allocated to Out-of-Home (OOH) media.\n",
      "\n",
      "In terms of budget allocation, the campaign's actual spend of €187,500 was below the planned budget of €200,000, representing a 6.25% underspend. While this may indicate some inefficiencies in the campaign's execution, it also presents an opportunity to reallocate funds to high-performing channels in future campaigns. To maximize ROI, it is\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed multi-section report\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED REPORT SECTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "detailed_report = report_generator.generate_detailed_report(\n",
    "    campaign_metrics,\n",
    "    sections=[\"Overview\", \"Performance Analysis\", \"Recommendations\"]\n",
    ")\n",
    "\n",
    "for section, content in detailed_report.items():\n",
    "    print(f\"\\n--- {section.upper()} ---\\n\")\n",
    "    print(content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7222d91",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Create a Custom Report Template\n",
    "\n",
    "Design and implement a custom report template for a specific use case.\n",
    "\n",
    "Requirements:\n",
    "- Create a new template with both static and dynamic sections\n",
    "- Include both data fields and LLM-generated narrative\n",
    "- Support at least 5 data fields\n",
    "- Test with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948e57d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:18:01.741978Z",
     "start_time": "2025-12-09T16:18:01.731015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3.1: Your solution here\n",
    "\n",
    "# TODO: Define your custom report template\n",
    "CUSTOM_TEMPLATE = \"\"\"\n",
    "# Your template here\n",
    "# Use {field_name} for dynamic values\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Create test data\n",
    "custom_data = {\n",
    "    # Your data fields\n",
    "}\n",
    "\n",
    "# TODO: Generate the report using ReportGenerator or a custom approach\n",
    "\n",
    "# See solutions.py for reference implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a61de",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: LangChain Agentic Framework\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. It provides abstractions for:\n",
    "\n",
    "- **Models**: Unified interface for different LLM providers\n",
    "- **Prompts**: Templates and management for prompts\n",
    "- **Chains**: Combining multiple components sequentially\n",
    "- **Agents**: Autonomous systems that decide which actions to take\n",
    "- **Tools**: Functions that agents can use to interact with the world\n",
    "\n",
    "Reference: https://docs.langchain.com/oss/python/langchain/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848594c1a5bf70bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:18:21.042741Z",
     "start_time": "2025-12-09T16:18:17.429429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_google_genai\r\n",
      "  Downloading langchain_google_genai-4.0.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\r\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting google-genai<2.0.0,>=1.53.0 (from langchain_google_genai)\r\n",
      "  Downloading google_genai-1.54.0-py3-none-any.whl.metadata (47 kB)\r\n",
      "Collecting langchain-core<2.0.0,>=1.1.2 (from langchain_google_genai)\r\n",
      "  Downloading langchain_core-1.1.3-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain_google_genai) (2.12.5)\r\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.53.0->langchain_google_genai) (4.10.0)\r\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (2.43.0)\r\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.53.0->langchain_google_genai) (0.28.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.53.0->langchain_google_genai) (2.32.5)\r\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.53.0->langchain_google_genai) (9.1.2)\r\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.53.0->langchain_google_genai) (15.0.1)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.53.0->langchain_google_genai) (4.15.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (3.11)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (1.3.0)\r\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (6.2.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (0.4.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (4.9.1)\r\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (2025.10.5)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (0.4.53)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (25.0)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (6.0.2)\r\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (0.12.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (3.0.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (3.11.4)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain_google_genai) (0.25.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.4.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (3.4.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (2.5.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.53.0->langchain_google_genai) (0.6.1)\r\n",
      "Downloading langchain_google_genai-4.0.0-py3-none-any.whl (63 kB)\r\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Downloading google_genai-1.54.0-py3-none-any.whl (262 kB)\r\n",
      "Downloading langchain_core-1.1.3-py3-none-any.whl (475 kB)\r\n",
      "Installing collected packages: filetype, langchain-core, google-genai, langchain_google_genai\r\n",
      "\u001b[2K  Attempting uninstall: langchain-core\r\n",
      "\u001b[2K    Found existing installation: langchain-core 1.1.0\r\n",
      "\u001b[2K    Uninstalling langchain-core-1.1.0:\r\n",
      "\u001b[2K      Successfully uninstalled langchain-core-1.1.0\r\n",
      "\u001b[2K  Attempting uninstall: google-genaim━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\r\n",
      "\u001b[2K    Found existing installation: google-genai 1.52.0━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\r\n",
      "\u001b[2K    Uninstalling google-genai-1.52.0:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\r\n",
      "\u001b[2K      Successfully uninstalled google-genai-1.52.0━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [langchain_google_genai]e-genai]\r\n",
      "\u001b[1A\u001b[2KSuccessfully installed filetype-1.2.0 google-genai-1.54.0 langchain-core-1.1.3 langchain_google_genai-4.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_google_genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5fe5d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:18:09.399464Z",
     "start_time": "2025-12-09T16:18:07.314680Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/Academy/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_google_genai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import LangChain components\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage, AIMessage\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, MessagesPlaceholder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_google_genai'"
     ]
    }
   ],
   "source": [
    "# Import LangChain components\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e17053f0252ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (removed broken import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain models\n",
    "llm_groq = None\n",
    "llm_gemini = None\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    llm_groq = ChatGroq(\n",
    "        api_key=GROQ_API_KEY,\n",
    "        model_name=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"LangChain Groq model initialized\")\n",
    "\n",
    "if GEMINI_API_KEY:\n",
    "    llm_gemini = ChatGoogleGenerativeAI(\n",
    "        google_api_key=GEMINI_API_KEY,\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"LangChain Gemini model initialized\")\n",
    "\n",
    "# Select default model\n",
    "llm = llm_groq if llm_groq else llm_gemini\n",
    "print(f\"\\nDefault LangChain model: {'Groq' if llm_groq else 'Gemini'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c58e1",
   "metadata": {},
   "source": [
    "---\n",
    "## Application 1: Conversational Assistant with LangChain\n",
    "\n",
    "LangChain provides a more structured approach to building conversational assistants with built-in memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Create a simple conversational chain with memory\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a professional advertising campaign analyst.\n",
    "Your role is to help marketing professionals understand and optimize their campaigns.\n",
    "Be concise, data-driven, and use industry-standard terminology.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# Store for managing session histories\n",
    "session_histories = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    \"\"\"Get or create a session history.\"\"\"\n",
    "    if session_id not in session_histories:\n",
    "        session_histories[session_id] = InMemoryChatMessageHistory()\n",
    "    return session_histories[session_id]\n",
    "\n",
    "# Create runnable with history\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the conversational chain\n",
    "print(\"=\" * 60)\n",
    "print(\"LANGCHAIN CONVERSATIONAL ASSISTANT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "session_id = \"demo_session\"\n",
    "\n",
    "# First message\n",
    "response1 = conversational_chain.invoke(\n",
    "    {\"input\": \"I have a TV campaign with 48% reach and frequency of 3.5. What is the GRP?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(f\"\\nUser: I have a TV campaign with 48% reach and frequency of 3.5. What is the GRP?\")\n",
    "print(f\"\\nAssistant: {response1.content}\")\n",
    "\n",
    "# Follow-up (context should be maintained)\n",
    "response2 = conversational_chain.invoke(\n",
    "    {\"input\": \"How does that compare to industry benchmarks?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\\nUser: How does that compare to industry benchmarks?\")\n",
    "print(f\"\\nAssistant: {response2.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29119721",
   "metadata": {},
   "source": [
    "---\n",
    "## Application 2: Document Analysis Agent with Tools\n",
    "\n",
    "LangChain agents can use tools to perform specific tasks. This is particularly useful for document analysis where we need structured extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for document analysis\n",
    "\n",
    "@tool\n",
    "def extract_dates(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract all dates mentioned in the text.\n",
    "    Use this tool when you need to find campaign periods or deadlines.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r'\\d{4}-\\d{2}-\\d{2}',  # YYYY-MM-DD\n",
    "        r'\\d{1,2}/\\d{1,2}/\\d{4}',  # DD/MM/YYYY or MM/DD/YYYY\n",
    "        r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},?\\s+\\d{4}',\n",
    "    ]\n",
    "    \n",
    "    dates_found = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        dates_found.extend(matches)\n",
    "    \n",
    "    if dates_found:\n",
    "        return f\"Dates found: {', '.join(dates_found)}\"\n",
    "    return \"No dates found in the text.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def extract_monetary_values(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract monetary values and currencies from the text.\n",
    "    Use this tool when you need to find budgets, costs, or prices.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r'(?:EUR|USD|GBP|\\$|\\u20ac|\\u00a3)\\s*[\\d,]+(?:\\.\\d{2})?',\n",
    "        r'[\\d,]+(?:\\.\\d{2})?\\s*(?:EUR|USD|GBP|euros?|dollars?)',\n",
    "    ]\n",
    "    \n",
    "    values_found = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        values_found.extend(matches)\n",
    "    \n",
    "    if values_found:\n",
    "        return f\"Monetary values found: {', '.join(values_found)}\"\n",
    "    return \"No monetary values found in the text.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def extract_percentages(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract percentage values from the text.\n",
    "    Use this tool when you need to find reach, frequency, or performance metrics.\n",
    "    \"\"\"\n",
    "    pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        return f\"Percentages found: {', '.join(matches)}\"\n",
    "    return \"No percentages found in the text.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def analyze_sentiment(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze the overall sentiment and tone of the document.\n",
    "    Use this to understand if a report is positive, negative, or neutral.\n",
    "    \"\"\"\n",
    "    positive_words = ['success', 'exceeded', 'growth', 'improved', 'excellent', 'strong', 'achieved']\n",
    "    negative_words = ['failed', 'declined', 'below', 'poor', 'missed', 'weak', 'challenge']\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        sentiment = \"positive\"\n",
    "    elif neg_count > pos_count:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    \n",
    "    return f\"Document sentiment: {sentiment} (positive indicators: {pos_count}, negative indicators: {neg_count})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d12d2609688e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the document analysis agent\n",
    "tools = [extract_dates, extract_monetary_values, extract_percentages, analyze_sentiment]\n",
    "\n",
    "# Define system prompt (updated pattern per Lesson 4)\n",
    "agent_system_prompt = \"\"\"You are a document analysis assistant specialized in advertising campaign documents.\n",
    "\n",
    "Analyze documents using the available tools. Workflow:\n",
    "1. Identify relevant information to extract\n",
    "2. Use the appropriate tools to extract specific information\n",
    "3. Synthesize the extracted information into a coherent summary\n",
    "4. Highlight the most important findings\n",
    "\n",
    "Always call tools when extraction is possible.\"\"\"\n",
    "\n",
    "# Create the agent with the modern API\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=agent_system_prompt,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67a60d2c945d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the document analysis agent\n",
    "analysis_document = \"\"\"\n",
    "CAMPAIGN PERFORMANCE REPORT - Q4 2024\n",
    "\n",
    "Campaign Period: October 1, 2024 - December 31, 2024\n",
    "Total Investment: EUR 180,000\n",
    "\n",
    "Key Results:\n",
    "- Reach achieved: 52.3% (target was 50%)\n",
    "- Average frequency: 4.1\n",
    "- Campaign GRP: 214.4\n",
    "\n",
    "The campaign showed strong performance, exceeding the reach target by 2.3 percentage points.\n",
    "Digital channels achieved 38% reach while TV contributed 45% reach with some overlap.\n",
    "\n",
    "Budget utilization was at 92%, with the remaining 8% to be reallocated to Q1 2025.\n",
    "Overall, the campaign achieved its primary objectives of brand awareness growth.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DOCUMENT ANALYSIS AGENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query = f\"\"\"Analyze this campaign report and extract all key information:\\n\\n{analysis_document}\\n\\nProvide a summary of:\\n1. All dates found\\n2. All monetary values\\n3. All percentages\\n4. The overall sentiment of the report\"\"\"\n",
    "\n",
    "# Stream the agent reasoning and final answer\n",
    "for chunk in agent.stream({\"messages\": [{\"role\": \"user\", \"content\": query}]}, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb84dbd2143ca8",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Extend the Document Analysis Agent\n",
    "\n",
    "Add a new tool to the document analysis agent.\n",
    "\n",
    "Requirements:\n",
    "- Create a new @tool function\n",
    "- The tool should extract or analyze a specific type of information\n",
    "- Integrate it with the existing agent\n",
    "- Test with a sample document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097e22b305646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2: Your solution here\n",
    "\n",
    "# TODO: Create a new tool\n",
    "# @tool\n",
    "# def your_new_tool(text: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Description of what this tool does.\n",
    "#     \"\"\"\n",
    "#     # Your implementation\n",
    "#     pass\n",
    "\n",
    "# TODO: Add the tool to the agent and test\n",
    "# extended_tools = tools + [your_new_tool]\n",
    "# extended_agent = create_agent(model=llm, tools=extended_tools, system_prompt=agent_system_prompt, debug=True)\n",
    "\n",
    "# See solutions.py for reference implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf81c9ae45d28db",
   "metadata": {},
   "source": [
    "---\n",
    "## Application 3: Report Generation Agent\n",
    "\n",
    "An agent that can generate comprehensive reports by using tools to gather data and format output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a79d8cf0e1457f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for report generation\n",
    "\n",
    "# Simulated database of campaign data\n",
    "CAMPAIGN_DATABASE = {\n",
    "    \"Q4_2024\": {\n",
    "        \"name\": \"Q4 2024 Brand Campaign\",\n",
    "        \"client\": \"TechCorp\",\n",
    "        \"period\": {\"start\": \"2024-10-01\", \"end\": \"2024-12-31\"},\n",
    "        \"budget\": {\"planned\": 200000, \"spent\": 185000, \"currency\": \"EUR\"},\n",
    "        \"performance\": {\n",
    "            \"reach\": 52.3,\n",
    "            \"reach_target\": 50.0,\n",
    "            \"frequency\": 4.1,\n",
    "            \"impressions\": 6200000,\n",
    "            \"grp\": 214.4\n",
    "        }\n",
    "    },\n",
    "    \"Q3_2024\": {\n",
    "        \"name\": \"Q3 2024 Summer Campaign\",\n",
    "        \"client\": \"TechCorp\",\n",
    "        \"period\": {\"start\": \"2024-07-01\", \"end\": \"2024-09-30\"},\n",
    "        \"budget\": {\"planned\": 150000, \"spent\": 148500, \"currency\": \"EUR\"},\n",
    "        \"performance\": {\n",
    "            \"reach\": 45.2,\n",
    "            \"reach_target\": 48.0,\n",
    "            \"frequency\": 3.8,\n",
    "            \"impressions\": 5100000,\n",
    "            \"grp\": 171.8\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_campaign_data(campaign_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve campaign data from the database.\n",
    "    Use this to get performance metrics, budget information, and other campaign details.\n",
    "    Available campaigns: Q4_2024, Q3_2024\n",
    "    \"\"\"\n",
    "    if campaign_id in CAMPAIGN_DATABASE:\n",
    "        data = CAMPAIGN_DATABASE[campaign_id]\n",
    "        return json.dumps(data, indent=2)\n",
    "    return f\"Campaign '{campaign_id}' not found. Available: {list(CAMPAIGN_DATABASE.keys())}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_campaign_kpis(impressions: int, budget_spent: float, reach: float) -> str:\n",
    "    \"\"\"\n",
    "    Calculate key performance indicators for a campaign.\n",
    "    Provide impressions (total), budget_spent (in currency), and reach (percentage).\n",
    "    Returns CPM and cost per reach point.\n",
    "    \"\"\"\n",
    "    if impressions <= 0 or budget_spent <= 0 or reach <= 0:\n",
    "        return \"Error: All values must be positive numbers.\"\n",
    "    \n",
    "    cpm = (budget_spent / impressions) * 1000\n",
    "    cost_per_reach_point = budget_spent / reach\n",
    "    \n",
    "    return f\"\"\"Campaign KPIs:\n",
    "- CPM (Cost per Mille): {cpm:.2f}\n",
    "- Cost per Reach Point: {cost_per_reach_point:.2f}\n",
    "- Impressions per Euro: {impressions / budget_spent:.1f}\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def compare_campaigns(campaign_id_1: str, campaign_id_2: str) -> str:\n",
    "    \"\"\"\n",
    "    Compare two campaigns and provide a performance comparison.\n",
    "    Use this when asked to compare campaigns or analyze trends.\n",
    "    \"\"\"\n",
    "    if campaign_id_1 not in CAMPAIGN_DATABASE or campaign_id_2 not in CAMPAIGN_DATABASE:\n",
    "        return f\"One or both campaigns not found. Available: {list(CAMPAIGN_DATABASE.keys())}\"\n",
    "    \n",
    "    c1 = CAMPAIGN_DATABASE[campaign_id_1]\n",
    "    c2 = CAMPAIGN_DATABASE[campaign_id_2]\n",
    "    \n",
    "    comparison = {\n",
    "        \"campaigns\": [campaign_id_1, campaign_id_2],\n",
    "        \"reach_comparison\": {\n",
    "            campaign_id_1: c1[\"performance\"][\"reach\"],\n",
    "            campaign_id_2: c2[\"performance\"][\"reach\"],\n",
    "            \"difference\": c1[\"performance\"][\"reach\"] - c2[\"performance\"][\"reach\"]\n",
    "        },\n",
    "        \"frequency_comparison\": {\n",
    "            campaign_id_1: c1[\"performance\"][\"frequency\"],\n",
    "            campaign_id_2: c2[\"performance\"][\"frequency\"],\n",
    "            \"difference\": c1[\"performance\"][\"frequency\"] - c2[\"performance\"][\"frequency\"]\n",
    "        },\n",
    "        \"budget_utilization\": {\n",
    "            campaign_id_1: f\"{c1['budget']['spent'] / c1['budget']['planned'] * 100:.1f}%\",\n",
    "            campaign_id_2: f\"{c2['budget']['spent'] / c2['budget']['planned'] * 100:.1f}%\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return json.dumps(comparison, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7c80600e343e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the report generation agent\n",
    "report_tools = [\n",
    "    get_campaign_data, \n",
    "    calculate_campaign_kpis, \n",
    "    compare_campaigns\n",
    "]\n",
    "\n",
    "report_agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a professional report generation assistant for advertising campaigns.\n",
    "\n",
    "Your capabilities:\n",
    "1. Retrieve campaign data from the database\n",
    "2. Calculate performance KPIs\n",
    "3. Compare campaigns\n",
    "\n",
    "When generating reports:\n",
    "- Always start by retrieving the relevant campaign data\n",
    "- Calculate KPIs when performance analysis is needed\n",
    "- Use compare_campaigns when asked about trends or comparisons\n",
    "- Structure the output professionally\n",
    "\n",
    "Be thorough but concise in your analysis.\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "# Create the agent with the modern API\n",
    "report_system_prompt = \"\"\"You are a professional report generation assistant for advertising campaigns.\n",
    "\n",
    "Your capabilities:\n",
    "1. Retrieve campaign data from the database\n",
    "2. Calculate performance KPIs\n",
    "3. Compare campaigns\n",
    "\n",
    "When generating reports:\n",
    "- Always start by retrieving the relevant campaign data\n",
    "- Calculate KPIs when performance analysis is needed\n",
    "- Use compare_campaigns when asked about trends or comparisons\n",
    "- Structure the output professionally\n",
    "\n",
    "Be thorough but concise in your analysis.\"\"\"\n",
    "\n",
    "report_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=report_tools,\n",
    "    system_prompt=report_system_prompt,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b4b2e48539c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the report generation agent\n",
    "print(\"=\" * 60)\n",
    "print(\"REPORT GENERATION AGENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report_query = (\n",
    "    \"Generate a performance report for Q4_2024 campaign that includes:\\n\"\n",
    "    \"1. Campaign overview\\n\"\n",
    "    \"2. Key performance metrics and KPIs\\n\"\n",
    "    \"3. Comparison with Q3_2024 campaign\\n\"\n",
    "    \"4. Brief recommendations for future campaigns\"\n",
    ")\n",
    "\n",
    "for chunk in report_agent.stream({\"messages\": [{\"role\": \"user\", \"content\": report_query}]}, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14feec37a79e1031",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Build a Complete Report Generation System\n",
    "\n",
    "Create an enhanced report generation agent with additional tools.\n",
    "\n",
    "Requirements:\n",
    "- Add at least 2 new tools (e.g., trend analysis, forecast, visualization suggestions)\n",
    "- Create a comprehensive report for a given campaign\n",
    "- Include executive summary and detailed analysis sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f7412371b4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.2: Your solution here\n",
    "\n",
    "# TODO: Create new tools for enhanced reporting\n",
    "# @tool\n",
    "# def analyze_trend(...) -> str:\n",
    "#     \"\"\"...\"\"\"\n",
    "#     pass\n",
    "\n",
    "# @tool\n",
    "# def generate_forecast(...) -> str:\n",
    "#     \"\"\"...\"\"\"\n",
    "#     pass\n",
    "\n",
    "# TODO: Create enhanced agent with new tools\n",
    "# enhanced_report_tools = report_tools + [analyze_trend, generate_forecast]\n",
    "# enhanced_report_agent = create_agent(model=llm, tools=enhanced_report_tools, system_prompt=report_system_prompt, debug=True)\n",
    "\n",
    "# TODO: Test with a comprehensive report request\n",
    "\n",
    "# See solutions.py for reference implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3568b",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned to build three fundamental LLM applications:\n",
    "\n",
    "### Part 1: Direct LLM Integration\n",
    "1. **Conversational Assistants**: Managing context and conversation history\n",
    "2. **Document Analysis**: Extracting structured data with schema validation\n",
    "3. **Report Generation**: Creating professional documents from data\n",
    "\n",
    "### Part 2: LangChain Framework\n",
    "1. **Conversational Chains**: Using LangChain's memory management\n",
    "2. **Tool-Using Agents**: Creating autonomous agents with specialized tools\n",
    "3. **Multi-Step Workflows**: Combining tools for complex report generation\n",
    "\n",
    "### Key Takeaways\n",
    "- LangChain provides higher-level abstractions that simplify agent development\n",
    "- Tools extend agent capabilities beyond pure text generation\n",
    "- Proper prompt engineering is essential for both approaches\n",
    "- Schema validation ensures reliable structured output\n",
    "- Template-based approaches provide consistency in generated content\n",
    "\n",
    "### Next Steps\n",
    "- Complete the exercises to reinforce your understanding\n",
    "- Experiment with different LLM providers and models\n",
    "- Explore LangChain documentation for additional features\n",
    "- Consider adding error handling and monitoring for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064ae68",
   "metadata": {},
   "source": [
    "---\n",
    "## Solutions\n",
    "\n",
    "All exercise solutions are available in `solutions.py`. To check your answers:\n",
    "\n",
    "```python\n",
    "from solutions import (\n",
    "    # Exercise 1.1\n",
    "    exercise_1_1_solution,\n",
    "    \n",
    "    # Exercise 2.1\n",
    "    exercise_2_1_solution,\n",
    "    \n",
    "    # Exercise 2.2\n",
    "    exercise_2_2_solution,\n",
    "    \n",
    "    # Exercise 3.1\n",
    "    exercise_3_1_solution,\n",
    "    \n",
    "    # Exercise 3.2\n",
    "    exercise_3_2_solution\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
